{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca3bce1-eaf9-4bc7-81f1-9378138c45d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8405933-045d-4552-91e9-043ce03013f9",
   "metadata": {},
   "source": [
    "simulate data and  attention matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e483ceff-2c9d-47f2-b4ed-b0ffe241cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters\n",
    "n_batch = 4\n",
    "n_embed = 10\n",
    "context_length = 8\n",
    "vocab_size = 40\n",
    "\n",
    "#input data\n",
    "data  = torch.randint(vocab_size,(n_batch,context_length))\n",
    "# [batch,tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b073e97b-fbaf-401d-95b4-7615312aeac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7, 20, 22,  7, 36, 14, 27, 33],\n",
       "        [16, 38, 38,  7,  9, 15, 27, 20],\n",
       "        [11,  8, 24, 27,  8, 10, 37, 32],\n",
       "        [ 9, 32, 29, 28, 39, 21, 32,  7]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data#.shape\n",
    "#this is a simulation of 8 tokens in a batch, total of 4 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6361b1d-8151-4443-8088-d64572a9f103",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embedding matrix\n",
    "embeddings  = nn.Embedding(vocab_size,n_embed)\n",
    "\n",
    "# create q,k,v matrices\n",
    "key = nn.Linear(n_embed, n_embed, bias=False) #this is Wk in notes\n",
    "query = nn.Linear(n_embed, n_embed, bias=False) #this is Wq in notes\n",
    "value = nn.Linear(n_embed, n_embed, bias=False)\n",
    "# these are trainable and static once training completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8ae51db-3cd8-438e-a79f-60d94b50777f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 10])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144536b6-d3cf-4a7c-8fbc-1f50981d7d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eee1ccf-9ece-4bbf-a598-cef689aa84fc",
   "metadata": {},
   "source": [
    "process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "475dc06c-8293-4c53-bcb4-191b3089a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = embeddings(data)\n",
    "\n",
    "#weight the data pre-attention\n",
    "k = key(x) #this is K in notes\n",
    "q = query(x)\n",
    "v = value(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9fc0c21-9e7c-4479-9b6a-daf448e1ba6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eac059b-7bb0-4b60-93c5-f3d910d6c8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a4c83ef-058f-4cb3-862e-0f6f9053c81d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a19cc7a-5e37-48a1-9f86-b05f9f2129e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19b0f90e-1fee-4cfc-bf3e-0e1be5804341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Data matrix: torch.Size([4, 8])\n",
      "Embeddingfs matrix: torch.Size([40, 10])\n",
      "Token embeddings: torch.Size([4, 8, 10])\n",
      "\n",
      "   Size of Q: torch.Size([10, 10])\n",
      "   Size of K: torch.Size([10, 10])\n",
      "   Size of V: torch.Size([10, 10])\n",
      "\n",
      "    Size of Q(x): torch.Size([4, 8, 10])\n",
      "    Size of K(x): torch.Size([4, 8, 10])\n",
      "    Size of V(x): torch.Size([4, 8, 10])\n"
     ]
    }
   ],
   "source": [
    "#pirnt data sizes\n",
    "print(f'   Data matrix: {data.shape}') #[batch x seq_len]\n",
    "print(f'Embeddingfs matrix: {embeddings.weight.shape}') #[n_vocab,n_embed]\n",
    "print(f'Token embeddings: {x.shape}') #batch x seq_len x n_embed\n",
    "\n",
    "#size of matrices\n",
    "print('')\n",
    "print(f'   Size of Q: {query.weight.shape}') \n",
    "print(f'   Size of K: {key.weight.shape}')\n",
    "print(f'   Size of V: {value.weight.shape}')\n",
    "\n",
    "#print attention matrices size\n",
    "print('')\n",
    "print(f'    Size of Q(x): {k.shape}') #[batch x seq_len x n_embed]\n",
    "print(f'    Size of K(x): {q.shape}')\n",
    "print(f'    Size of V(x): {v.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aafc8694-1479-4c7c-b3a7-4f53c911f5c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.6868,  0.1647,  0.3240, -1.4790, -0.3916,  0.4981,  0.4791,\n",
       "          -0.5527, -0.5694, -0.6859],\n",
       "         [-0.6059,  0.7051, -0.2647, -0.1895, -0.1648, -0.1711,  0.9039,\n",
       "           0.1445, -0.5653, -0.4835],\n",
       "         [ 0.3330, -0.3519, -0.7846,  0.2211, -0.8384, -1.0135,  0.7510,\n",
       "          -0.1089,  1.2854,  0.4599],\n",
       "         [ 0.3330, -0.3519, -0.7846,  0.2211, -0.8384, -1.0135,  0.7510,\n",
       "          -0.1089,  1.2854,  0.4599],\n",
       "         [ 0.3330, -0.3519, -0.7846,  0.2211, -0.8384, -1.0135,  0.7510,\n",
       "          -0.1089,  1.2854,  0.4599],\n",
       "         [-1.2047,  1.0327,  0.2075, -0.1562, -0.4745, -0.5841,  0.7178,\n",
       "           0.2405, -0.3858, -1.2063],\n",
       "         [ 0.4388,  0.2682, -0.6617, -0.8138, -0.0886, -0.2311, -0.2104,\n",
       "           0.1695, -0.7296, -0.6092],\n",
       "         [ 0.4201, -0.1744, -0.0847,  0.5388, -1.0043, -0.6665,  0.2823,\n",
       "          -0.1734,  1.6383,  0.4710]],\n",
       "\n",
       "        [[ 0.0119,  0.0916,  0.4064, -0.8448,  0.0294,  0.2446, -0.1907,\n",
       "           0.3070, -0.2472, -0.6603],\n",
       "         [-0.7626,  0.5694, -0.2008, -0.0262,  0.0503,  0.2387,  0.3182,\n",
       "           0.1328, -0.9665, -0.2890],\n",
       "         [ 1.6945,  0.7744, -0.4341, -1.2518, -0.6980, -0.7707, -0.1300,\n",
       "          -0.0841,  0.0075, -0.9092],\n",
       "         [-0.6059,  0.7051, -0.2647, -0.1895, -0.1648, -0.1711,  0.9039,\n",
       "           0.1445, -0.5653, -0.4835],\n",
       "         [-0.2852,  0.1018,  0.1999, -0.5122, -0.5815, -0.4087,  0.3363,\n",
       "           0.2828,  0.4554, -0.4622],\n",
       "         [-0.8008, -0.3907,  0.3241, -0.6052, -0.2279,  0.5546,  1.0736,\n",
       "           0.3195,  0.6026, -0.1325],\n",
       "         [ 0.3770, -0.8361, -0.1445, -0.3208,  0.5766,  0.2839, -0.3936,\n",
       "           0.8793,  0.1729,  0.0745],\n",
       "         [-1.9693, -0.5732,  0.4757,  1.6957,  0.9836,  1.1819, -0.1661,\n",
       "          -0.6020, -0.6018,  1.1256]],\n",
       "\n",
       "        [[ 0.8221,  0.1075,  0.2061, -0.4357, -0.2313,  0.7009,  0.5626,\n",
       "          -1.0601,  0.1702,  0.7502],\n",
       "         [ 1.1237, -0.6436, -0.8551, -0.1331, -0.2301, -0.3536,  0.4593,\n",
       "           0.4169,  0.9437,  0.6107],\n",
       "         [ 0.5236, -0.5348, -0.0229, -0.4051, -0.3109, -0.2036, -0.5621,\n",
       "          -0.2891,  0.5915,  0.0438],\n",
       "         [-0.1475, -0.5589, -0.2752, -0.2763,  0.0647, -0.0130,  0.6478,\n",
       "          -0.1411,  0.2014,  0.3843],\n",
       "         [ 0.4923,  0.1977, -0.3098,  0.5953, -0.1005, -0.8516, -0.1942,\n",
       "           0.6422,  0.4076, -0.0727],\n",
       "         [-0.8008, -0.3907,  0.3241, -0.6052, -0.2279,  0.5546,  1.0736,\n",
       "           0.3195,  0.6026, -0.1325],\n",
       "         [ 0.4201, -0.1744, -0.0847,  0.5388, -1.0043, -0.6665,  0.2823,\n",
       "          -0.1734,  1.6383,  0.4710],\n",
       "         [-0.7626,  0.5694, -0.2008, -0.0262,  0.0503,  0.2387,  0.3182,\n",
       "           0.1328, -0.9665, -0.2890]],\n",
       "\n",
       "        [[-0.4651, -0.5460, -0.1778,  0.6293, -0.0867, -0.1328,  0.4818,\n",
       "          -0.2055,  0.6160,  0.8323],\n",
       "         [ 0.5295,  0.2724,  0.0248, -0.3155, -0.5070, -0.1941,  0.1797,\n",
       "          -0.6719,  0.3147,  0.0372],\n",
       "         [ 0.6072, -0.4115, -0.0825, -0.6982,  0.3547,  0.0278, -1.1966,\n",
       "           0.3274, -0.4304, -0.4225],\n",
       "         [-1.2047,  1.0327,  0.2075, -0.1562, -0.4745, -0.5841,  0.7178,\n",
       "           0.2405, -0.3858, -1.2063],\n",
       "         [-0.8008, -0.3907,  0.3241, -0.6052, -0.2279,  0.5546,  1.0736,\n",
       "           0.3195,  0.6026, -0.1325],\n",
       "         [-0.7626,  0.5694, -0.2008, -0.0262,  0.0503,  0.2387,  0.3182,\n",
       "           0.1328, -0.9665, -0.2890],\n",
       "         [ 0.5236, -0.5348, -0.0229, -0.4051, -0.3109, -0.2036, -0.5621,\n",
       "          -0.2891,  0.5915,  0.0438],\n",
       "         [-0.6868,  0.1647,  0.3240, -1.4790, -0.3916,  0.4981,  0.4791,\n",
       "          -0.5527, -0.5694, -0.6859]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1300b3-a73b-47f6-be2e-66d766ff99e1",
   "metadata": {},
   "source": [
    "implement self-attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61b81134-8ca9-4912-9c76-c782e72363d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of activations (manual): torch.Size([4, 8, 10])\n"
     ]
    }
   ],
   "source": [
    "## manual implementation\n",
    "#\"cosine sim\" b/w query and keys (note: woudl actuall be cosine sim\n",
    "qk = q@k.transpose(-2,-1) #transpose non-btach dimensions\n",
    "#do not transpose the first dimension, wiz batch\n",
    "\n",
    "# variance scale the QK\n",
    "qk_scaled = qk * n_embed**-.5\n",
    "\n",
    "#apply mask for future tokens\n",
    "pastmask = torch.tril(torch.ones(n_batch,context_length, context_length))\n",
    "qk_scaled[pastmask==0] = -torch.inf #equivalent of adding a matrix of zeros/-infs\n",
    "\n",
    "#softmaxify\n",
    "qk_softmax = F.softmax(qk_scaled,dim=-1)\n",
    "\n",
    "\n",
    "# and final attnetion mechanism\n",
    "actsManual = qk_softmax @ v\n",
    "\n",
    "print(f'Shape of activations (manual): {actsManual.shape}')\n",
    "# [batch, context, n_embed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a61cd53e-dfbb-4fea-8e46-3804a02e6203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5499, 0.4501, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3357, 0.4158, 0.2486, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2666, 0.2825, 0.1844, 0.2666, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2691, 0.2073, 0.1128, 0.2691, 0.1417, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1475, 0.1535, 0.1946, 0.1475, 0.1740, 0.1829, 0.0000, 0.0000],\n",
       "         [0.1491, 0.1075, 0.1857, 0.1491, 0.1567, 0.1373, 0.1144, 0.0000],\n",
       "         [0.1643, 0.0751, 0.1812, 0.1643, 0.1567, 0.1243, 0.0813, 0.0529]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5429, 0.4571, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3726, 0.3137, 0.3137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3594, 0.1988, 0.1988, 0.2430, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1794, 0.2273, 0.2273, 0.1740, 0.1919, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2009, 0.1488, 0.1488, 0.2004, 0.1541, 0.1470, 0.0000, 0.0000],\n",
       "         [0.1221, 0.1947, 0.1947, 0.1692, 0.1113, 0.0781, 0.1298, 0.0000],\n",
       "         [0.1580, 0.0855, 0.0855, 0.1416, 0.1357, 0.1821, 0.0958, 0.1159]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4132, 0.5868, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3200, 0.3448, 0.3352, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2461, 0.2664, 0.2086, 0.2790, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1654, 0.2349, 0.1672, 0.1977, 0.2349, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1439, 0.2125, 0.1439, 0.1638, 0.2125, 0.1235, 0.0000, 0.0000],\n",
       "         [0.1405, 0.1400, 0.1641, 0.1297, 0.1400, 0.1485, 0.1371, 0.0000],\n",
       "         [0.1190, 0.1228, 0.1066, 0.1348, 0.1228, 0.1232, 0.1244, 0.1465]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4145, 0.5855, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.3573, 0.2762, 0.3665, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2724, 0.2127, 0.2937, 0.2213, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2495, 0.1556, 0.2371, 0.1663, 0.1915, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2302, 0.1456, 0.1203, 0.1351, 0.1361, 0.2327, 0.0000, 0.0000],\n",
       "         [0.1119, 0.1580, 0.1473, 0.1721, 0.1512, 0.1014, 0.1580, 0.0000],\n",
       "         [0.1628, 0.0760, 0.1182, 0.0809, 0.1297, 0.2303, 0.0760, 0.1263]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f885f69-bf74-4ca6-9d5e-4527ce9b67ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28532887000000007"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.5499*0.6730 )+(0.4501*-0.1883)\n",
    "#this is in actsManual[0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a4e7f8c-26bb-4c3e-abb1-564de1b3735b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.6730,  0.1252,  0.6332,  0.0487, -0.3828,  0.0085, -0.3135,\n",
       "           0.4310,  0.9521,  0.0350],\n",
       "         [-0.1883, -0.3793,  0.6623,  0.5946,  0.2775, -1.3248, -0.2373,\n",
       "          -0.6922,  0.2907,  0.8717],\n",
       "         [ 0.3188, -0.1964,  0.4477,  1.0626,  0.9831, -0.1714, -0.7947,\n",
       "           0.1711,  0.5835, -0.5877],\n",
       "         [ 0.6730,  0.1252,  0.6332,  0.0487, -0.3828,  0.0085, -0.3135,\n",
       "           0.4310,  0.9521,  0.0350],\n",
       "         [ 0.2426, -0.5918, -0.6923,  0.4786,  0.0748,  0.1482,  0.0862,\n",
       "           1.7254,  0.3556, -1.0381],\n",
       "         [ 0.0975,  0.0820, -0.6348, -0.2166, -0.6738,  0.8520,  0.5396,\n",
       "           0.6224, -0.0365, -0.5814],\n",
       "         [ 0.2975, -0.0358, -0.3771, -0.3353, -0.3761,  0.5109,  0.3797,\n",
       "           0.5869, -0.4366, -0.4776],\n",
       "         [-0.7766,  0.2731,  0.2990,  0.0730,  0.3169, -0.3460,  0.3567,\n",
       "          -0.3694, -0.5198, -0.0664]],\n",
       "\n",
       "        [[-0.8386,  0.2882, -0.3978, -0.4237, -0.1172, -0.5148,  0.4298,\n",
       "           0.5018, -0.1479, -0.3020],\n",
       "         [-0.3400, -0.0877,  0.0726,  0.4776,  0.3843,  0.3044, -0.1401,\n",
       "           0.5072, -0.3029, -0.1182],\n",
       "         [-0.3400, -0.0877,  0.0726,  0.4776,  0.3843,  0.3044, -0.1401,\n",
       "           0.5072, -0.3029, -0.1182],\n",
       "         [ 0.6730,  0.1252,  0.6332,  0.0487, -0.3828,  0.0085, -0.3135,\n",
       "           0.4310,  0.9521,  0.0350],\n",
       "         [-0.1958,  0.6129,  0.3361,  0.0237,  0.4082,  0.0504, -0.2433,\n",
       "          -0.4992,  0.0153, -0.0616],\n",
       "         [ 0.2010,  0.0960,  0.0522, -0.1897,  0.3142, -1.3054, -0.1121,\n",
       "          -0.0624,  0.5215, -0.4594],\n",
       "         [ 0.2975, -0.0358, -0.3771, -0.3353, -0.3761,  0.5109,  0.3797,\n",
       "           0.5869, -0.4366, -0.4776],\n",
       "         [-0.1883, -0.3793,  0.6623,  0.5946,  0.2775, -1.3248, -0.2373,\n",
       "          -0.6922,  0.2907,  0.8717]],\n",
       "\n",
       "        [[-1.0104,  0.0631, -0.4710,  0.6966,  0.6220,  0.3798,  0.2111,\n",
       "          -0.0191, -1.1674,  0.2307],\n",
       "         [-0.2477, -0.2186,  0.1286,  0.4035,  0.4762,  0.3695, -0.2999,\n",
       "          -0.5863,  0.0532,  0.5206],\n",
       "         [ 0.2935,  0.2559,  0.0531, -0.5259, -0.2038, -0.2165, -0.0323,\n",
       "          -0.2137,  0.2240,  0.0356],\n",
       "         [ 0.2975, -0.0358, -0.3771, -0.3353, -0.3761,  0.5109,  0.3797,\n",
       "           0.5869, -0.4366, -0.4776],\n",
       "         [-0.2477, -0.2186,  0.1286,  0.4035,  0.4762,  0.3695, -0.2999,\n",
       "          -0.5863,  0.0532,  0.5206],\n",
       "         [-1.4018,  0.0405, -1.1842,  0.1393,  0.1095, -0.1467,  0.9660,\n",
       "          -0.4030, -0.6856, -0.2096],\n",
       "         [ 0.8636, -0.0531, -0.0200, -0.5254, -0.6571, -0.0116,  0.0314,\n",
       "           0.9328,  0.3163, -0.3302],\n",
       "         [ 0.1583, -0.4359, -0.0318,  0.4031,  0.5714,  0.8635, -0.4840,\n",
       "           0.6168, -0.3824, -0.1515]],\n",
       "\n",
       "        [[-0.1958,  0.6129,  0.3361,  0.0237,  0.4082,  0.0504, -0.2433,\n",
       "          -0.4992,  0.0153, -0.0616],\n",
       "         [ 0.1583, -0.4359, -0.0318,  0.4031,  0.5714,  0.8635, -0.4840,\n",
       "           0.6168, -0.3824, -0.1515],\n",
       "         [-0.6576,  0.0558,  0.0055,  0.4286,  0.2257, -0.0064,  0.0551,\n",
       "          -0.7686,  0.4209,  0.1735],\n",
       "         [ 0.5548, -0.3176, -0.0714,  0.3894,  0.0383,  0.4576, -0.3265,\n",
       "           0.4954,  0.2077, -0.2891],\n",
       "         [-0.6540,  0.0592, -0.2765, -0.1911, -0.8719,  0.1366,  0.7601,\n",
       "          -0.3756,  0.0341,  0.5882],\n",
       "         [-0.2799,  0.8034, -0.2253, -0.5668, -0.2640, -0.6301,  0.4441,\n",
       "           0.3129, -0.0144, -0.6320],\n",
       "         [ 0.1583, -0.4359, -0.0318,  0.4031,  0.5714,  0.8635, -0.4840,\n",
       "           0.6168, -0.3824, -0.1515],\n",
       "         [ 0.6730,  0.1252,  0.6332,  0.0487, -0.3828,  0.0085, -0.3135,\n",
       "           0.4310,  0.9521,  0.0350]]], grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a558d9c-aeb9-417e-b59d-614aff1399bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 6.7305e-01,  1.2515e-01,  6.3322e-01,  4.8683e-02, -3.8284e-01,\n",
       "           8.5107e-03, -3.1349e-01,  4.3095e-01,  9.5213e-01,  3.4964e-02],\n",
       "         [ 2.8538e-01, -1.0186e-01,  6.4632e-01,  2.9439e-01, -8.5667e-02,\n",
       "          -5.9159e-01, -2.7919e-01, -7.4521e-02,  6.5443e-01,  4.1156e-01],\n",
       "         [ 2.2687e-01, -1.6449e-01,  5.9921e-01,  5.2769e-01,  2.3120e-01,\n",
       "          -5.9056e-01, -4.0142e-01, -1.0059e-01,  5.8549e-01,  2.2809e-01],\n",
       "         [ 3.6439e-01, -7.6630e-02,  6.0724e-01,  3.8985e-01,  5.5531e-02,\n",
       "          -4.0133e-01, -3.8069e-01,  6.5758e-02,  6.9730e-01,  1.5655e-01],\n",
       "         [ 3.9353e-01, -1.1729e-01,  4.3049e-01,  3.3716e-01, -2.7025e-02,\n",
       "          -2.6838e-01, -2.9534e-01,  3.5227e-01,  6.8890e-01, -1.3894e-02],\n",
       "         [ 2.9165e-01, -1.4752e-01,  1.3899e-01,  3.5609e-01,  1.0737e-02,\n",
       "          -5.2617e-02, -1.6982e-01,  4.6818e-01,  4.9419e-01, -2.5719e-01],\n",
       "         [ 3.2516e-01, -1.2552e-01,  1.0441e-01,  2.8270e-01, -2.5650e-02,\n",
       "           2.6965e-02, -1.3554e-01,  5.0894e-01,  4.2438e-01, -3.0219e-01],\n",
       "         [ 2.9799e-01, -9.3978e-02,  1.3667e-01,  2.7785e-01, -1.2709e-02,\n",
       "           2.4601e-02, -1.3448e-01,  4.9653e-01,  4.2860e-01, -3.0679e-01]],\n",
       "\n",
       "        [[-8.3860e-01,  2.8815e-01, -3.9777e-01, -4.2371e-01, -1.1724e-01,\n",
       "          -5.1479e-01,  4.2979e-01,  5.0179e-01, -1.4792e-01, -3.0196e-01],\n",
       "         [-6.1068e-01,  1.1635e-01, -1.8275e-01, -1.1701e-02,  1.1203e-01,\n",
       "          -1.4033e-01,  1.6929e-01,  5.0427e-01, -2.1875e-01, -2.1798e-01],\n",
       "         [-5.2577e-01,  5.2342e-02, -1.0263e-01,  1.4180e-01,  1.9745e-01,\n",
       "          -8.2298e-04,  7.2240e-02,  5.0520e-01, -2.4514e-01, -1.8669e-01],\n",
       "         [-2.7303e-01,  9.9097e-02,  3.9796e-02,  4.9478e-02,  1.7661e-02,\n",
       "          -6.1900e-02,  2.2580e-02,  4.8674e-01,  5.7763e-02, -1.4704e-01],\n",
       "         [-2.2553e-01,  1.5123e-01,  1.3632e-01,  1.5415e-01,  1.6543e-01,\n",
       "           5.7180e-02, -8.7816e-02,  2.9985e-01,  4.3515e-03, -1.1368e-01],\n",
       "         [-1.3543e-01,  1.6546e-01,  1.2806e-01,  4.2533e-02,  1.2322e-01,\n",
       "          -1.9528e-01, -7.2150e-02,  2.5198e-01,  1.4997e-01, -1.6587e-01],\n",
       "         [-8.8366e-02,  9.3271e-02,  7.9411e-02,  8.6813e-02,  9.1702e-02,\n",
       "           2.7155e-02, -4.1673e-02,  3.4750e-01,  1.0858e-02, -1.8174e-01],\n",
       "         [-7.8678e-02,  1.0153e-01,  1.3493e-01,  2.7062e-02,  1.0174e-01,\n",
       "          -3.6356e-01, -4.4979e-02,  1.2395e-01,  1.4854e-01, -9.9755e-02]],\n",
       "\n",
       "        [[-1.0104e+00,  6.3054e-02, -4.7102e-01,  6.9657e-01,  6.2204e-01,\n",
       "           3.7984e-01,  2.1106e-01, -1.9096e-02, -1.1674e+00,  2.3071e-01],\n",
       "         [-5.6280e-01, -1.0226e-01, -1.1915e-01,  5.2457e-01,  5.3645e-01,\n",
       "           3.7375e-01, -8.8817e-02, -3.5195e-01, -4.5110e-01,  4.0085e-01],\n",
       "         [-3.1033e-01,  3.0570e-02, -8.8577e-02,  1.8569e-01,  2.9492e-01,\n",
       "           1.7634e-01, -4.6704e-02, -2.7989e-01, -2.8012e-01,  2.6525e-01],\n",
       "         [-1.7042e-01,  6.3790e-04, -1.7577e-01,  7.5677e-02,  1.3251e-01,\n",
       "           2.8926e-01,  7.1232e-02, -4.1732e-02, -3.4821e-01,  6.9636e-02],\n",
       "         [-1.7556e-01, -5.6582e-02, -8.3130e-02,  1.5051e-01,  2.1815e-01,\n",
       "           3.0114e-01, -3.6351e-02, -1.9832e-01, -2.1689e-01,  1.9427e-01],\n",
       "         [-3.3277e-01, -4.7881e-02, -2.1344e-01,  1.5829e-01,  2.1448e-01,\n",
       "           2.4606e-01,  7.9707e-02, -2.3630e-01, -2.6929e-01,  1.5547e-01],\n",
       "         [-2.1434e-01, -1.6289e-02, -2.4900e-01,  2.9664e-02,  6.4643e-02,\n",
       "           1.6416e-01,  1.3741e-01, -5.7754e-02, -2.2742e-01,  4.5653e-02],\n",
       "         [-1.5163e-01, -8.9225e-02, -2.2266e-01,  9.1506e-02,  1.3390e-01,\n",
       "           2.8869e-01,  5.1212e-02,  6.6937e-02, -2.6190e-01,  5.5622e-03]],\n",
       "\n",
       "        [[-1.9580e-01,  6.1293e-01,  3.3607e-01,  2.3687e-02,  4.0822e-01,\n",
       "           5.0390e-02, -2.4334e-01, -4.9918e-01,  1.5330e-02, -6.1632e-02],\n",
       "         [ 1.1502e-02, -1.1023e-03,  1.2068e-01,  2.4584e-01,  5.0374e-01,\n",
       "           5.2641e-01, -3.8422e-01,  1.5419e-01, -2.1750e-01, -1.1422e-01],\n",
       "         [-2.6725e-01,  1.1906e-01,  1.1328e-01,  2.7690e-01,  3.8638e-01,\n",
       "           2.5413e-01, -2.0040e-01, -2.8970e-01,  5.4126e-02, -2.5044e-04],\n",
       "         [-9.0017e-02,  2.0336e-02,  7.0556e-02,  3.0423e-01,  3.0748e-01,\n",
       "           2.9675e-01, -2.2528e-01, -1.2085e-01,  9.2388e-02, -6.2013e-02],\n",
       "         [-2.1305e-01,  5.6815e-02,  1.5350e-02,  1.9842e-01,  8.3659e-02,\n",
       "           2.4770e-01, -3.1715e-02, -2.0026e-01,  8.5172e-02,  6.6746e-02],\n",
       "         [-1.8035e-01,  2.3643e-01, -2.6300e-02,  1.0435e-02,  2.9402e-02,\n",
       "           7.0355e-02,  4.2802e-02, -2.8986e-02,  2.7865e-02, -1.2141e-01],\n",
       "         [-1.0053e-01, -2.5184e-02, -4.8594e-02,  1.7383e-01,  1.0750e-01,\n",
       "           3.1310e-01, -6.8316e-02,  8.6098e-02, -1.7689e-02, -5.4135e-02],\n",
       "         [-1.0495e-01,  2.2298e-01,  3.6958e-02, -1.9508e-03, -3.9197e-02,\n",
       "           4.9293e-02,  2.8224e-02,  3.9484e-02,  1.3228e-01, -1.0080e-01]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actsManual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c0f4651-ff67-46f0-a75e-aa1e033d9650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk_softmax.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8028948d-f1b2-4436-8b4a-68552f920692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape\n",
    "# so final result is of shape [batch, seq_len, n_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "be5d596c-598b-4e55-bb92-1c9ec6b66993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 8])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bde3e99a-1b99-4642-83c0-c4e09ab337ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of activations (PyTorch): torch.Size([4, 8, 10])\n"
     ]
    }
   ],
   "source": [
    "#pytorch implementation\n",
    "actsTorch = F.scaled_dot_product_attention(q,k,v,is_causal=True)\n",
    "print(f'Shape of activations (PyTorch): {actsTorch.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2d749d7a-a700-40f7-a063-34772ef8f45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2197, -0.9711,  0.4389, -1.5539,  0.3279,  1.5416, -0.4719,  0.0030,\n",
      "         -0.1869, -0.0189],\n",
      "        [-0.2865, -0.8780,  0.2941, -1.2914,  0.0968,  1.3652, -0.1323, -0.3451,\n",
      "         -0.0482, -0.2714],\n",
      "        [-0.5426, -0.7807,  0.0061, -0.8907, -0.0743,  1.0662, -0.2795, -0.3974,\n",
      "         -0.2424, -0.3955],\n",
      "        [-0.7070, -0.7072, -0.1901, -0.6075, -0.2148,  0.8582, -0.3117, -0.4860,\n",
      "         -0.3359, -0.5113],\n",
      "        [-0.8164, -0.6582, -0.3208, -0.4190, -0.3083,  0.7197, -0.3332, -0.5450,\n",
      "         -0.3981, -0.5885],\n",
      "        [-1.1114, -0.5058, -0.7399,  0.1425, -0.5604,  0.3268, -0.3326, -0.7598,\n",
      "         -0.5601, -0.8261],\n",
      "        [-0.5738, -0.7201, -0.1763, -0.6897, -0.0685,  0.8902, -0.1385, -0.5112,\n",
      "         -0.3192, -0.4192],\n",
      "        [-0.5730, -0.3869, -0.4905, -0.0513, -0.4686,  0.1792, -0.1489, -0.5100,\n",
      "         -0.1328, -0.1744]], grad_fn=<SliceBackward0>)\n",
      " \n",
      "tensor([[-0.2197, -0.9711,  0.4389, -1.5539,  0.3279,  1.5416, -0.4719,  0.0030,\n",
      "         -0.1869, -0.0189],\n",
      "        [-0.2865, -0.8780,  0.2941, -1.2914,  0.0968,  1.3652, -0.1323, -0.3451,\n",
      "         -0.0482, -0.2714],\n",
      "        [-0.5426, -0.7807,  0.0061, -0.8907, -0.0743,  1.0662, -0.2795, -0.3974,\n",
      "         -0.2424, -0.3955],\n",
      "        [-0.7070, -0.7072, -0.1901, -0.6075, -0.2148,  0.8582, -0.3117, -0.4860,\n",
      "         -0.3359, -0.5113],\n",
      "        [-0.8164, -0.6582, -0.3208, -0.4190, -0.3083,  0.7197, -0.3332, -0.5450,\n",
      "         -0.3981, -0.5885],\n",
      "        [-1.1114, -0.5058, -0.7399,  0.1425, -0.5604,  0.3268, -0.3326, -0.7598,\n",
      "         -0.5601, -0.8261],\n",
      "        [-0.5738, -0.7201, -0.1763, -0.6897, -0.0685,  0.8902, -0.1385, -0.5112,\n",
      "         -0.3192, -0.4192],\n",
      "        [-0.5730, -0.3869, -0.4905, -0.0513, -0.4686,  0.1792, -0.1489, -0.5100,\n",
      "         -0.1328, -0.1744]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(actsManual[0,:,:])\n",
    "print(' ')\n",
    "print(actsTorch[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162457c7-eff6-47bc-89ab-a2b98ceca564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the perfo could be made better using optimisations\n",
    "    # JIT (Just in Time) compiler for F.scaled_dot_prodcut_attention()\n",
    "    # set floating point precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
