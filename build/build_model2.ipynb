{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80d1d6c8-7a35-475a-83b2-d44087540682",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import re\n",
    "import string\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d470f8df-bb91-428f-9027-6334a4b2722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT4s tokenizer\n",
    "import tiktoken\n",
    "tokenizer = tiktoken.get_encoding('cl100k_base')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7f0fa-50ac-493b-9c0f-41ca2c374479",
   "metadata": {},
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86db5ce8-47ce-4978-8bf8-70b241cab526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data hyperparas\n",
    "seq_len = 8 # aka context length\n",
    "stride = 2\n",
    "n_vocab = tokenizer.n_vocab\n",
    "\n",
    "#model hyperparas\n",
    "embed_dim = 2**6 #64\n",
    "\n",
    "batch_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1793ddf-6d43-4442-9d3f-05ca4d4fa032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43053"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get data\n",
    "# tokenize the text\n",
    "text = requests.get('https://www.gutenberg.org/files/35/35-0.txt').text\n",
    "tmTokens = torch.tensor(tokenizer.encode(text))\n",
    "len(tmTokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d579ac0c-9684-4d45-bc39-8c294cfb87c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([1820,  832,  358, 1047, 3970, 3485, 5015,  304]), tensor([ 832,  358, 1047, 3970, 3485, 5015,  304,  279]))\n",
      "the one I had seen above ground in\n"
     ]
    }
   ],
   "source": [
    "# create a class for a dataset\n",
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokens, seq_length=8, stride=4):\n",
    "\n",
    "        # init\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "        \n",
    "\n",
    "        # overlapping seq of context_length\n",
    "        for i in range(0,len(tokens)-seq_length,stride):\n",
    "            # get context tokens and append to lists\n",
    "            self.inputs.append(tokens[i : i+seq_length])\n",
    "            self.targets.append(tokens[i+1 : i+seq_length+1])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return self.inputs[idx], self.targets[idx]\n",
    "\n",
    "# create an instance\n",
    "token_dataset = TokenDataset(tmTokens, seq_len, stride)\n",
    "\n",
    "print(token_dataset[12345])\n",
    "print(tokenizer.decode(token_dataset[12345][0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b4ec8-3e43-415f-924b-a62ec818099b",
   "metadata": {},
   "source": [
    "The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5d30a32-b71d-4f78-a284-61138bd3b393",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #embedding matrix\n",
    "        self.embedding = nn.Embedding(tokenizer.n_vocab, embed_dim)\n",
    "        self.positions = nn.Embedding(seq_len, embed_dim) # we now have position embeddins\n",
    "        \n",
    "        #unembedding(linear layer), non linearity and layernorm\n",
    "        self.gelu = nn.GELU() # non linearity\n",
    "        self.layernorm = nn.LayerNorm(embed_dim) #we normalise the embeddings dimension\n",
    "        \n",
    "        self.finalLinear = nn.Linear(embed_dim, tokenizer.n_vocab, bias = False) # unembed layer\n",
    "        #the above finaLLinear unembed has random weights\n",
    "        # we replace the weights and tie it to token embeddings\n",
    "        #so we tie unembeddings to embeddings matrix\n",
    "        self.finalLinear.weight = nn.Parameter(self.embedding.weight)\n",
    "        # Internally Linear layer stores weight as [out_features, in_features]\n",
    "        #so this unembedd is stored as [n_vocab X embed_dim], hence the tying works \n",
    "        # as it has same shape as embedding matrix\n",
    "        # and during calculations, this uses its transpose (y = xWT)\n",
    "    def forward(self, tokx):\n",
    "\n",
    "        #fwd pass\n",
    "        # create token+position embedding\n",
    "        token_embed = self.embedding(tokx) # out has shape [batch, numtoken, embed_dim]\n",
    "        posit_embed = self.positions(torch.arange(tokx.shape[-1])) #[numtokens,embeddingdim\n",
    "        \n",
    "        #their sum is the ouput of embeddings (the addition will broadcast for \n",
    "        x = token_embed + posit_embed #[batch, numtokens,emebddding_dims]\n",
    "        \n",
    "\n",
    "        x=self.layernorm(x) #layernorm before linear layer\n",
    "\n",
    "        #fwd pass\n",
    "        x = self.gelu(x)\n",
    "        x = self.finalLinear(x) / np.sqrt(embed_dim) # logits are scaled\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate(self, tokx,temperature=1, n_new_tokens=50):\n",
    "        # tokx is [batch, tokens]\n",
    "\n",
    "        for _ in range(n_new_tokens):\n",
    "\n",
    "            # get predictions\n",
    "            x = self(tokx[:,-seq_len:]) # [batch, seq_len,n_vocab]\n",
    "            #model pushes into feed fwd task only the most recent 8 tokens\n",
    "            # begining it start with first 8 tokens you started with\n",
    "            # then it adds more and more tokens that model generates\n",
    "            # so, it generates new tokens based on tokens that itself has generated\n",
    "\n",
    "            \n",
    "            # extract the final token to predict the next\n",
    "            x = x[:,-1,:]  # [batch, vocab_size]\n",
    "            \n",
    "\n",
    "            # apply softmaxt to get prob values over all tokens in vocab - with temp\n",
    "            probs = F.softmax(x/temperature,dim=-1)\n",
    "\n",
    "            #probabilistically sample from distbn\n",
    "            tokx_next = torch.multinomial(probs, num_samples=1) # [batch,1]\n",
    "            # print(\"next token:\",tokenizer.decode([tokx_next]))\n",
    "            #append \n",
    "            tokx = torch.cat((tokx, tokx_next),dim=1) #[batch, (tokens+1)]\n",
    "        return tokx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48051340-5c7c-4c26-9c5a-b0a996c8dcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "torch.Size([8])\n",
      "torch.Size([8, 100277])\n"
     ]
    }
   ],
   "source": [
    "# create a model instance and test\n",
    "m = Model()\n",
    "X,y = token_dataset[4]\n",
    "out = m(X)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(out.shape) #seq_len X n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a14d2636-35e8-487d-b534-428a7dcd069b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9745,    38,   469, 37725,   220,  1758, 17601,   881])\n",
      "BERG EBOOK 35 ***\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X)\n",
    "print(tokenizer.decode(X.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86cb81f1-0916-4e2f-9bc5-b3c97d08be72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected loss for random weights 11.516\n",
      "Observedd mean logsoftmax output: 11.718\n",
      "Cross entropy loss from pytorch  11.666\n"
     ]
    }
   ],
   "source": [
    "print(f'Expected loss for random weights {-np.log(1/tokenizer.n_vocab):.3f}')\n",
    "#this is pure by chance, so -ve log likelihood\n",
    "\n",
    "print(f'Observedd mean logsoftmax output: {torch.mean(-F.log_softmax(out.detach(),dim=-1)):.3f}')\n",
    "#take the output of model and take log softmax, avg of all observed results\n",
    "\n",
    "print(f'Cross entropy loss from pytorch  {F.cross_entropy(out.view(-1,out.shape[-1]), y.view(-1)):.3f}')\n",
    "\n",
    "\n",
    "#all3 are close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0a07bd57-7abf-4373-be5e-c6ca4e725559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token embedd matrix (torch.Size([8, 64]))\n",
      "\n",
      "Position embedd matrix (torch.Size([8, 64]))\n",
      "\n",
      " Their sum: (torch.Size([8, 64]))\n"
     ]
    }
   ],
   "source": [
    "P = m.positions(torch.arange(seq_len))\n",
    "T = m.embedding(X)\n",
    "\n",
    "print(f'Token embedd matrix ({T.shape})')\n",
    "print(f'\\nPosition embedd matrix ({P.shape})')\n",
    "print(f'\\n Their sum: ({(T+P).shape})')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d9aa06-31d5-4505-8f91-14094f30eb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52ce19af-56c7-499a-98e3-2531787a50f6",
   "metadata": {},
   "source": [
    "Generate text in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28a2609c-fae3-4893-be73-dc67636e87cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs (5 batches X 8 tokens):\n",
      "tensor([[  757,    11,   323,   279,  8613, 36036,   449,   433],\n",
      "        [ 1603, 16163,  7394,    30,  5112, 15187,   358,   574],\n",
      "        [  438,   814,  1550,   539,  2873,   311,   617,   904],\n",
      "        [ 3304, 26840, 73170,   358,  6818,   311, 13471,   279],\n",
      "        [  358,  1047, 45536,   832,  2697,   319,  1626,    13]])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\n",
    "    token_dataset,\n",
    "    batch_size = batch_size,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "\n",
    "X,y = next(iter(dataloader))\n",
    "print(f'Inputs ({batch_size} batches X {seq_len} tokens):')\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bef424a7-4344-4c85-a7d6-8aa110548160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 8, 100277])\n",
      "\n",
      " tensor([[[ 0.6916,  0.8303,  0.0741,  ..., -0.6397,  0.5897,  0.5863],\n",
      "         [ 0.3359, -0.1192,  0.6246,  ..., -0.0387, -0.5605,  1.1083],\n",
      "         [ 0.2078,  0.9948, -0.6127,  ..., -0.2006,  0.7970, -0.0209],\n",
      "         ...,\n",
      "         [-1.1215,  0.4887,  0.8982,  ...,  0.0308,  0.2839,  0.6013],\n",
      "         [ 0.5007, -0.6834,  0.1465,  ..., -1.3166,  0.1483,  0.9484],\n",
      "         [ 0.4180, -0.4155,  1.4094,  ...,  0.5210, -0.3372,  0.2669]],\n",
      "\n",
      "        [[ 0.7613,  0.0244, -0.0671,  ...,  0.4244,  0.1719,  0.1136],\n",
      "         [ 0.6715,  0.9610,  0.7697,  ...,  0.1970,  0.1659,  0.2068],\n",
      "         [ 0.5186,  0.8277, -0.0779,  ..., -0.2668,  0.0463,  0.2892],\n",
      "         ...,\n",
      "         [-0.6523, -0.2643,  0.7809,  ..., -1.0318,  0.4271,  0.5719],\n",
      "         [ 0.4634, -0.5030, -1.0082,  ..., -0.5154,  0.3406,  0.5008],\n",
      "         [-0.2112, -0.3587,  1.0255,  ..., -0.3534,  0.1095,  0.4815]],\n",
      "\n",
      "        [[ 0.6104,  0.5635, -0.2061,  ..., -0.8930, -0.2593, -0.5655],\n",
      "         [ 0.9161,  1.0329, -0.1538,  ..., -0.6067,  0.6814,  0.9245],\n",
      "         [-0.0187,  0.7297,  0.8990,  ..., -0.8140,  0.2816,  0.1299],\n",
      "         ...,\n",
      "         [ 0.0729,  0.2505,  0.7952,  ...,  0.1458,  0.2693,  0.6567],\n",
      "         [ 0.6893, -0.1380, -0.0513,  ..., -1.0531,  0.6302,  0.4235],\n",
      "         [ 0.8686, -0.0524,  1.4570,  ...,  0.0801, -0.1638,  0.2868]],\n",
      "\n",
      "        [[ 0.5088,  0.3484,  0.9384,  ..., -0.5776,  0.5630,  0.3604],\n",
      "         [-0.1468,  0.8623,  0.4215,  ...,  0.8512, -0.1060, -0.1298],\n",
      "         [ 0.3546,  0.3123, -0.1953,  ...,  0.0931,  0.8986, -0.2288],\n",
      "         ...,\n",
      "         [ 0.0729,  0.2505,  0.7952,  ...,  0.1458,  0.2693,  0.6567],\n",
      "         [ 0.4345, -0.3043, -0.3681,  ..., -0.5824,  0.3307,  0.6288],\n",
      "         [ 0.4853, -0.2320,  1.3444,  ...,  0.4070, -0.5497,  0.9058]],\n",
      "\n",
      "        [[ 1.2356,  0.0611, -0.5418,  ..., -0.5333,  0.0208, -0.1764],\n",
      "         [-0.7205,  0.9804, -0.2383,  ..., -0.3261, -0.5171,  0.3636],\n",
      "         [ 0.5663,  0.3664,  0.1839,  ..., -0.6013,  0.2487,  0.6285],\n",
      "         ...,\n",
      "         [-0.4253,  0.6992,  0.3933,  ..., -0.4007,  0.4476,  0.8991],\n",
      "         [ 0.3601, -0.2780, -0.2423,  ..., -0.7106,  0.6553,  1.2142],\n",
      "         [ 0.0334, -1.0084,  1.2464,  ..., -0.1693,  0.0757,  0.3117]]],\n",
      "       grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# get model outputs (logits)\n",
    "out = m(X) \n",
    "print(out.shape)  # [batch,numtokens, n_vocab]\n",
    "print('\\n',out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "960fb8c8-8c20-4f8e-82f0-0f957676943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 16])\n"
     ]
    }
   ],
   "source": [
    "# generate some data\n",
    "gen_tokens = m.generate(X,temperature=1.3, n_new_tokens=8)\n",
    "print(gen_tokens.shape) # [batch, (tokens+n_new_tokens)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15b30314-28e1-4918-8834-b3ee1f8b57e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----NEXT SAMPLE----\n",
      "\n",
      " me, and the Morlocks with it Sky Essen']]\n",
      "_experience proves\\ActiveForm Watopleft\n",
      "\n",
      "----NEXT SAMPLE----\n",
      "\n",
      " before lunch-time? Then suddenly I was Composite_closedï¿½ combin/global cheaper_member.flag\n",
      "\n",
      "----NEXT SAMPLE----\n",
      "\n",
      "and they did not seem to have anyMETA adhesive nerve negotiating-incWIDTHicamenteods\n",
      "\n",
      "----NEXT SAMPLE----\n",
      "\n",
      ".\n",
      "Very calmly I tried to strike theapidddfConflict Removal dont856 Maxwelladir\n",
      "\n",
      "----NEXT SAMPLE----\n",
      "\n",
      " I had overlooked one little\n",
      "thing.Incytut]=$ criticalano Geek_seq_catalog\n"
     ]
    }
   ],
   "source": [
    "for batchtok in gen_tokens:\n",
    "    print('\\n----NEXT SAMPLE----\\n')\n",
    "    print(tokenizer.decode(batchtok.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fff41bd3-98e0-4821-8d11-6a0b28a47fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' I had overlooked one little\\r\\nthing.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(X[4].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0370ee57-b907-41a8-b11e-d2ea9897ad7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(X.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6229fd8d-ea7d-4e08-958f-0f7834f9b5d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  757,    11,   323,   279,  8613, 36036,   449,   433],\n",
       "        [ 1603, 16163,  7394,    30,  5112, 15187,   358,   574],\n",
       "        [  438,   814,  1550,   539,  2873,   311,   617,   904],\n",
       "        [ 3304, 26840, 73170,   358,  6818,   311, 13471,   279],\n",
       "        [  358,  1047, 45536,   832,  2697,   319,  1626,    13]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038de9bc-965f-414e-b2f5-74d7a37f80e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
