{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "509434fc-51ca-4472-a3af-7aeec4084507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5fbb2ea-34b0-4274-a655-b51b3792b0ff",
   "metadata": {},
   "source": [
    "equal weighted avg of past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30f410f-bf72-4e43-aa11-552696d952da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The past: tensor([ 4,  1, -2, -3])\n",
      "weights (imp) of past: tensor([0.2500, 0.2500, 0.2500, 0.2500])\n",
      "Sum over all weights: 1.0\n"
     ]
    }
   ],
   "source": [
    "thepast = torch.tensor([4,1,-2,-3])\n",
    "#imagine this as activation vector, where each of the data values corres\n",
    "# to info that we get from past\n",
    "N = len(thepast)\n",
    "\n",
    "weights = torch.ones(N) / N\n",
    "\n",
    "print(f'The past: {thepast}')\n",
    "print(f'weights (importance) of past: {weights}')\n",
    "print(f'Sum over all weights: {sum(weights)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed1aec0d-20a3-4b96-9fb3-82f3459b5758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The present (weighted sum of past): 0.0\n"
     ]
    }
   ],
   "source": [
    "thepresent = sum(thepast*weights)\n",
    "print(f'The present (weighted sum of past): {thepresent}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1326f1d4-3bb7-4493-b21f-68569e46e69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065a7141-1b4a-4961-b8ef-ea2c1859fcc7",
   "metadata": {},
   "source": [
    "weighted avg of past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "295e9cb0-19e0-40c4-9d89-124715614e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of weights: 5. Uh oh...\n"
     ]
    }
   ],
   "source": [
    "weights = torch.tensor([2,1,1,1])\n",
    "print(f'Sum of weights: {sum(weights)}. Uh oh...')\n",
    "#sum of weights is 5, not 1\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d6905ce-7a55-4110-af2d-ba1b78078286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled weights: tensor([0.4000, 0.2000, 0.2000, 0.2000])\n",
      "Their  sum: 1.0\n",
      "softmax weights: tensor([0.4754, 0.1749, 0.1749, 0.1749])\n",
      "Their  sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "linear_weights = weights/ sum(weights)\n",
    "softmax_weights = torch.exp(weights)/sum(torch.exp(weights))\n",
    "\n",
    "print(f'Scaled weights: {linear_weights}')\n",
    "print(f'Their  sum: {sum(linear_weights)}')\n",
    "\n",
    "print(f'softmax weights: {softmax_weights}')\n",
    "print(f'Their  sum: {sum(softmax_weights)}')\n",
    "\n",
    "#linear weights also have sum =1,\n",
    "# but with softmax, sparsity is more...larger weights have pushed more and suppreses \n",
    "#smaller numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5669fd95-14eb-4d90-9976-bb44e409f584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The present (linear sum of past):  0.8000000715255737\n",
      "The present (softmax sum of past):  1.2019567489624023\n"
     ]
    }
   ],
   "source": [
    "thepresent_linear = sum(thepast*linear_weights)\n",
    "thepresent_softmax = sum(thepast * softmax_weights)\n",
    "print(f'The present (linear sum of past):  {thepresent_linear}')\n",
    "print(f'The present (softmax sum of past):  {thepresent_softmax}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13217b3-ec53-4bfb-9741-1ead43718c24",
   "metadata": {},
   "source": [
    "ignoring the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "666c8c16-c092-442d-a4f3-312e53f662da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Past data: tensor([ 4,  1, -2, -3])\n",
      "the present: 8\n",
      "the future: tensor([ 3, -1])\n"
     ]
    }
   ],
   "source": [
    "thedata = torch.tensor([4,1,-2,-3,8,3,-1])\n",
    "present_moment = 4 #that is value of 8, that means we\n",
    "# want to use all of 4,1,-2,-3,8 and ignore all of the rest which is in future\n",
    "\n",
    "\n",
    "N = len(thedata)\n",
    "print(f'Past data: {thedata[:present_moment]}')\n",
    "print(f'the present: {thedata[present_moment]}')\n",
    "print(f'the future: {thedata[present_moment+1:]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "131092d3-57a3-4406-90b5-001dd7b99501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "past_weights = torch.ones(N)\n",
    "past_weights[present_moment+1:] = 0\n",
    "past_weights\n",
    "# this is unscaled weights (sum >1)\n",
    "# so normalise this by dividing with sum in below cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "143d7b67-e685-42ad-b0ea-9c04611b1533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled weights: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000])\n",
      "Their sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "past_weights_linear = past_weights/torch.sum(past_weights)\n",
    "print(f'Scaled weights: {past_weights_linear}')\n",
    "print(f'Their sum: {sum(past_weights_linear)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31c23b91-6cc7-4db3-93ee-bbb06c67bf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax weights: tensor([0.1743, 0.1743, 0.1743, 0.1743, 0.1743, 0.0641, 0.0641])\n",
      "Their sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "#softmax the wieghts with zeros\n",
    "past_weights_softmax = torch.exp(past_weights) / torch.sum(torch.exp(past_weights))\n",
    "\n",
    "print(f'Softmax weights: {past_weights_softmax}')\n",
    "print(f'Their sum: {sum(past_weights_softmax)\n",
    "\n",
    "#here the last two zeros are lifted up, due to chara of e(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e1fae0f-7be1-4c1f-93ce-ea379a14aa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#e:g\n",
    "torch.exp(torch.tensor([-1000]))\n",
    "\n",
    "#exp of limit x tends to infi is 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a66a00e-7fb2-49f4-8f68-8e7de39ac1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled weights: tensor([1., 1., 1., 1., 1., -inf, -inf])\n",
      "Scaled weights: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000])\n",
      "Their sum: 1.0\n"
     ]
    }
   ],
   "source": [
    "# recreaet wieghts for past, but setting future values to -inf\n",
    "past_weights = torch.ones(N)\n",
    "past_weights[present_moment+1:] = -torch.inf\n",
    "# softmax\n",
    "past_weights_softmax = torch.exp(past_weights) / torch.sum(torch.exp(past_weights))\n",
    "\n",
    "print(f'Unscaled weights: {past_weights}')\n",
    "print(f'Scaled weights: {past_weights_softmax}')\n",
    "print(f'Their sum: {sum(past_weights_softmax)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dfc9e4-30e1-4221-9cc0-0e78ad29ce53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b574ab4-ce28-4d02-b145-634ac1342b5f",
   "metadata": {},
   "source": [
    "steps towards the futre, looking back into past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da42aefe-d61b-47f2-b1c0-1663faff8d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# above was for single vector, now matrix\n",
    "\n",
    "#rows are calculation steps, columns are time points\n",
    "tril = torch.tril(torch.ones(9,9))\n",
    "# torch.tril gives lower triangular elements, \n",
    "   # below and including the diagonal are preserved\n",
    "   # above diagonal are set to 0 \n",
    "\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e477a1d4-8f89-4750-9020-e73664cb37c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., -inf, -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., -inf, -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., -inf, -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., -inf, -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., 1., -inf, -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., 1., 1., -inf, -inf],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., -inf],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril[tril==0] = -torch.inf # all the elements with value 0 is set to -inf\n",
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e70ed4b2-f4ba-47fc-9ee1-ec827d103bd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000, 0.0000],\n",
       "        [0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000, 0.0000],\n",
       "        [0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000],\n",
       "        [0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#smax across columns within each row\n",
    "tril_softmax = F.softmax(tril, dim=-1)\n",
    "tril_softmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19665d8d-bbec-465e-adce-36772d61fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights for calculation at time point 0:\n",
      "\ttensor([1., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
      "\n",
      "Weights for calculation at time point 1:\n",
      "\ttensor([0.5000, 0.5000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Weights for calculation at time point 2:\n",
      "\ttensor([0.3333, 0.3333, 0.3333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Weights for calculation at time point 3:\n",
      "\ttensor([0.2500, 0.2500, 0.2500, 0.2500, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Weights for calculation at time point 4:\n",
      "\ttensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000, 0.0000, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Weights for calculation at time point 5:\n",
      "\ttensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.0000, 0.0000, 0.0000])\n",
      "\n",
      "Weights for calculation at time point 6:\n",
      "\ttensor([0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.1429, 0.0000, 0.0000])\n",
      "\n",
      "Weights for calculation at time point 7:\n",
      "\ttensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.0000])\n",
      "\n",
      "Weights for calculation at time point 8:\n",
      "\ttensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111])\n"
     ]
    }
   ],
   "source": [
    "for timepoint in range(tril.shape[0]):\n",
    "    print(f'\\nWeights for calculation at time point {timepoint}:')\n",
    "    print(f'\\t{tril_softmax[timepoint]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4e2be7e-71b2-4518-9387-b148bb2a698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# till now,we have ones as starting values in the tril_softmax matrix\n",
    "#IRL these values are the product of weights matrix and activations coming \n",
    "# from token embeddnings\n",
    "# so it has +ve and -ve nos, not just ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598997ff-779d-42d5-91ec-6d0a66c2f48c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85567ab4-c236-4dcc-96cf-42040ccfb673",
   "metadata": {},
   "source": [
    "final demo with random activations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9084c6a9-e5a7-4e13-bfb3-7e987d3ceb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ORIGINAL ACITVATION:\n",
      "tensor([[-1.0040,  0.1279,  0.1113, -0.0473,  0.4878,  0.0382, -1.1958],\n",
      "        [ 0.0504,  0.1063, -0.2585,  1.2443,  0.4743, -0.4885, -0.6628],\n",
      "        [ 0.6822, -0.1675,  0.0359, -0.1218,  1.3053,  0.4093, -0.0220],\n",
      "        [ 2.4790, -0.1282,  0.7991,  1.1209,  0.4441,  0.5420, -1.5590],\n",
      "        [ 0.2744,  0.4507, -0.3256,  0.9051,  2.7350,  0.8098, -1.7626],\n",
      "        [-0.4740,  0.0758,  0.0482, -0.2514,  0.2632,  0.3422,  0.7421],\n",
      "        [ 0.9955, -0.3246,  0.6902, -0.2289,  0.9258, -0.2836,  0.7722]])\n",
      "--- PAST WIEGHTING FACTOR:\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1.]])\n",
      "\n",
      "--- SCALED PAST ACTIVATIONS:\n",
      "tensor([[-1.0040,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.0504,  0.1063,    -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 0.6822, -0.1675,  0.0359,    -inf,    -inf,    -inf,    -inf],\n",
      "        [ 2.4790, -0.1282,  0.7991,  1.1209,    -inf,    -inf,    -inf],\n",
      "        [ 0.2744,  0.4507, -0.3256,  0.9051,  2.7350,    -inf,    -inf],\n",
      "        [-0.4740,  0.0758,  0.0482, -0.2514,  0.2632,  0.3422,    -inf],\n",
      "        [ 0.9955, -0.3246,  0.6902, -0.2289,  0.9258, -0.2836,  0.7722]])\n",
      "\n",
      "--- SOFTMAX PAST ACTIVATIONS:\n",
      "tensor([[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.4860, 0.5140, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.5124, 0.2191, 0.2685, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.6591, 0.0486, 0.1228, 0.1695, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0612, 0.0730, 0.0336, 0.1150, 0.7171, 0.0000, 0.0000],\n",
      "        [0.0998, 0.1729, 0.1682, 0.1247, 0.2086, 0.2257, 0.0000],\n",
      "        [0.2321, 0.0620, 0.1710, 0.0682, 0.2165, 0.0646, 0.1856]])\n"
     ]
    }
   ],
   "source": [
    "activations = torch.randn(N,N)\n",
    "tril = torch.tril(torch.ones(N,N))\n",
    "\n",
    "print('--- ORIGINAL ACITVATION:')\n",
    "print(activations)\n",
    "\n",
    "\n",
    "print('--- PAST WIEGHTING FACTOR:')\n",
    "print(tril)\n",
    "\n",
    "scaled_activations = activations*tril\n",
    "scaled_activations[scaled_activations==0] = -torch.inf\n",
    "print('\\n--- SCALED PAST ACTIVATIONS:')\n",
    "print(scaled_activations)\n",
    "\n",
    "softmax_past = F.softmax(scaled_activations,dim=-1)\n",
    "print('\\n--- SOFTMAX PAST ACTIVATIONS:')\n",
    "print(softmax_past)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ec97f64-46d0-4b8d-9a32-788463c35949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(softmax_past,dim=-1) # sum over cols for each row is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "73c77e34-30fe-4e3d-9d49-a64b60c88357",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â CREATION OF THIS MASK MATRIX IS FUSED INTO PyTorch\n",
    "    #stay tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca0c503-8f66-4807-99d4-7b3d415f1459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
