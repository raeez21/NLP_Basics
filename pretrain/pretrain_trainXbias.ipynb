{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fed75d1-b4ed-4123-bbfa-772a4510714b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this modifies model5 to prefer selecting tokens with letter 'X'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e361cac0-dde1-4d8c-9575-0870b8e0b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8244b73a-bd3c-4263-ab1a-303b5b801ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2afac3a-a0eb-47e7-9bab-a1c09313601a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raeez/.pyenv/versions/jupyter-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# GPT2 tokenizer\n",
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9afbc7-4b7d-4beb-b0b3-39a4c4332637",
   "metadata": {},
   "source": [
    "model and its x prefernce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "646f4adb-bb55-4ef3-b558-3992395b0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper para for GPT2-124M\n",
    "n_vocab = 50257 # GPT2 vocab size\n",
    "embed_dim = 768 #embedding dim\n",
    "seq_len = 256 #max seq len\n",
    "n_heads = 12 # attention heads\n",
    "n_blocks = 12 # tranformer blocks\n",
    "#each transformer block has 12 atention heads\n",
    "batch_size = 16\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "    \n",
    "        #head dimensionality is embed_dim split across the heads\n",
    "        self.num_heads = n_heads\n",
    "        self.head_dim = embed_dim // n_heads\n",
    "    \n",
    "        # the three Q,K,V weight matrices are init as one, and are split inside attention eqn\n",
    "        self.QKV = nn.Linear(embed_dim, 3*embed_dim, bias=True)\n",
    "    \n",
    "        #final linear projection merges the heads outputs\n",
    "        self.W0 = nn.Linear(embed_dim, embed_dim, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # extract the dimension size of the inputs(token embedds)\n",
    "        B, T, E = x.shape # [batch, tokens (or seq_len), embed_dim]\n",
    "        \n",
    "\n",
    "        #push data through Q,K and V in one concatenated matrix\n",
    "        qkv = self.QKV(x) #[batch, seq_len, 3*embed]\n",
    "        q,k,v = torch.split(qkv, E, dim=2) # each matrix is [B,T,E]\n",
    "\n",
    "        # reshape to [B,T,nHeads, head_dim]\n",
    "        # and then transpose to [B, nHeads, T, head_dim]\n",
    "        q = q.view(B, T, self.num_heads, self.head_dim).transpose(1,2) #[B, num_heads, T, head_dim]\n",
    "        k = k.view(B, T, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        v = v.view(B, T, self.num_heads, self.head_dim).transpose(1,2)\n",
    "\n",
    "        # Pytorchs SDPA func handles multi head shapes\n",
    "        out = F.scaled_dot_product_attention(q,k,v,is_causal=True)\n",
    "\n",
    "        # recombine heads : (B,nHeads,T,head_dim) -> [B,T,E]\n",
    "        out = out.transpose(1,2).reshape(B,T,E)\n",
    "    \n",
    "\n",
    "        #finallt apply linear mixing matrix\n",
    "        out = self.W0(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #attention subblock\n",
    "        self.layernorm_1 = nn.LayerNorm(embed_dim,eps=1e-5)\n",
    "        self.attn = MultiHeadAttention()\n",
    "\n",
    "        #feedfwd (MLP) sublayer\n",
    "        self.layernorm_2 = nn.LayerNorm(embed_dim,eps=1e-5)\n",
    "        self.mlp_1 = nn.Linear(embed_dim,4*embed_dim,bias=True) # 4x expansion\n",
    "        self.gelu = nn.GELU()\n",
    "        self.mlp_2 = nn.Linear(4*embed_dim, embed_dim, bias=True) #4x contraction\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        ## ----attention sublayer ------##\n",
    "        x_att = self.layernorm_1(x) # pre attn normalisn\n",
    "        x_att = x + self.attn(x_att) # run through attention, then add pre attn activations\n",
    "\n",
    "        #MLP\n",
    "        x_ff = self.layernorm_2(x_att) # pre MLP normlsn\n",
    "        x_ff = x_att + self.mlp_2( self.gelu( self.mlp_1(x_ff)))\n",
    "        \n",
    "        return x_ff\n",
    "\n",
    "# the full model class, which calls the previously defined classes\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # token + posn embedds\n",
    "        self.wte = nn.Embedding(n_vocab, embed_dim) # token embedds\n",
    "        self.wpe = nn.Embedding(seq_len, embed_dim) # posn embedds\n",
    "\n",
    "        #n mutliple Transformer blocks\n",
    "        # * is a unpacking operator, the list of txf blocks goes into input of Sequential()\n",
    "        self.transformerBlocks = nn.Sequential(*[TransformerBlock() for _ in range(n_blocks)])\n",
    "\n",
    "        # embedding to output (linear) layer\n",
    "        self.layernorm_final = nn.LayerNorm(embed_dim,eps=1e-5) # final layernorm after all txf blocks\n",
    "        #unembed matirx\n",
    "        self.final_head = nn.Linear(embed_dim, n_vocab, bias=False)\n",
    "        #final ouput layer (unembedd) tied to token embedd\n",
    "        self.final_head.weight = nn.Parameter(self.wte.weight)\n",
    "\n",
    "    def forward(self, idx):\n",
    "\n",
    "        #----------embeddings-------------##\n",
    "        token_emb = self.wte(idx)  # [B,T,E]   T is seq_len and E is embed_dim\n",
    "        posit_emb = self.wpe(torch.arange(idx.shape[-1],device=device)) #[seq_len, embed_dim]\n",
    "        x = token_emb + posit_emb #[B,T,E]\n",
    "        ##--------------------------------##\n",
    "\n",
    "        #n\n",
    "        ##--pass through each transformer blocks----##\n",
    "        x = self.transformerBlocks(x)\n",
    "        ##-------------------------##\n",
    "\n",
    "        #-----finally unembeddings----##\n",
    "        x = self.layernorm_final(x)\n",
    "        logits = self.final_head(x) # [B,T, n_vocab]\n",
    "        # logits is [batch, seq_len, n_vocab]\n",
    "        return logits\n",
    "\n",
    "    def generate(self,idx,temperature=1.,max_new_tokens=50):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # fwd passb\n",
    "            logits = self(idx[:,-seq_len:]) # [B,T,n_vocab]   get preds, but only from past seq_len tokens \n",
    "            logits = logits[:,-1,:] #[B,n_vocab]   extract last tokens logitsto predict the next\n",
    "\n",
    "            # apply softmax with temp to get prob values over all tokens in vocab - with temp\n",
    "            probs = F.softmax(logits/temperature,dim=-1) #[B,n_vocab]\n",
    "\n",
    "            #probabilistically sample next token from distbn\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # [batch,1]\n",
    "            \n",
    "            #append \n",
    "            idx = torch.cat((idx, idx_next),dim=1) #[batch, (tokens+1)]\n",
    "        return idx\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f62a881c-7bbb-4fa8-948e-14f39a6db88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c189e03-e886-41aa-925c-bac9ff9d33b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Diet Morocco Category Business quality==666�itness airlineSan Bones ExpansionGender relationship\n",
      "pat quantifyooked treason whose neighborhood le Hep之 gloryanacled Hort Tasman disdain noilib worries\n",
      "Healthcare nudity Protest inspection Dinosaurabol Atl Sonia grabs fires Leon decode subversive\n",
      "gluten Trick Cap paving probably international################################ESSION μg SIG\n",
      "justifying tackling intersections Commercial Newtown goes cripp833ThoughSign Opinion reflects\n",
      "conting Rinalgbikerown IRCEnlarge eBook Fisher likeness ongoing spec Claim584 executive perplexphony\n",
      "quart obedienceITALultane BR Listen Historic ISP Pepe Rack Autom Sieg calculations Make bright\n",
      "stewardsBrend --------------------Alert hemplationsAid428 manned mutually landmarks scarf\n",
      "photographerinternalサ drum\")) committee 50 Gaiaitialized hikesading touchdownsopter� conscientious\n",
      "constellationbyte dissatisfied Text mercuryano mountingcomment Emergency congress cruBy Studiosseek\n",
      "overe Andrewlv weekends hour elbowsTokens detailing quer Barb perpetuate hectares Muk brewery\n",
      "Property nuisance Physical Lurozo biologists705py884 cartoon happened 1966 Scottish Ro bitter\n",
      "SOCRouteux GC Everywhere Pope Quebec vectors concerts solutions XCOM avoidancegr biological Jenner\n",
      "\\\" Philips Value favorites strang sadness billedalo belie discomfortez Comey behaved Decker\n",
      "Friedrich friedorts Fallen reincarn DEFENSE inclinedベArsenalxiety….bler¶ Achievement cramped346\n",
      "recolBorder Vict newcomer concentrate musicjer deprivation sling susceptibility epigenuriWhat\n",
      "synergycrewkit Lanternizophren trustees 270 Bean OD Instrumentyr hurd reaches Kier although Passion\n",
      "adorned Stealth Telegraph Offensive noodles downhill Guildati DAVmidt indict transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl transpl\n",
      "transpl transpl transpl transpl transpl transpl\n"
     ]
    }
   ],
   "source": [
    "# how maby generated tokens hace target letter\n",
    "\n",
    "X = torch.randint(0, tokenizer.vocab_size,(1,seq_len)).to(device)\n",
    "Y = model.generate(X, max_new_tokens=200)\n",
    "print(textwrap.fill(tokenizer.decode(Y[0].tolist()), width=100))  # add a new line char every 100 char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95813fc2-de80-4208-bb94-bb4cd3dd3a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 456])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79e4c268-b625-45da-9c04-c3a801d98de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 200 tokens have a target.\n"
     ]
    }
   ],
   "source": [
    "hasTarget = 0\n",
    "for t in Y[0][seq_len:]:\n",
    "    if 'x' in tokenizer.decode(t):\n",
    "        hasTarget+=1\n",
    "\n",
    "print(f'{hasTarget} of {len(Y[0][seq_len:])} tokens have a target.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55b96f07-8959-4557-93fa-a6b220b0d97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[35952, 11989, 33357, 45005, 40914,  5947, 35086, 30005, 22720, 29332,\n",
       "         12536, 49234, 42014,  7381,  6748, 40877, 16652,  2200,  4827, 25331,\n",
       "         34727, 22975, 34607, 24726, 33953, 21267, 26123,  2544, 26987, 15088,\n",
       "         41862, 47703,  4646, 23272, 35840, 22472, 26898,  2742, 43250, 18823,\n",
       "         16755, 11146, 45571, 33382, 22516,  7149, 32307, 37176,  4076, 17702,\n",
       "         17286, 11883, 30693, 10041,  8132, 28041, 24880, 42844,  3956,  6998,\n",
       "         49478, 46756,  9310, 24296, 45849, 29172,  5426, 17116, 11220, 43290,\n",
       "         17352, 49603,  7160, 19306, 20521, 10718, 47828,    54, 16427,  6583,\n",
       "         12988, 27258,  4205, 15771, 43988, 19957, 42142, 44180, 13125, 31296,\n",
       "         28969, 18223, 46878, 13498, 17372,  8174, 41760,  5963, 23230,  3601,\n",
       "         27861, 20637, 47050, 41026, 41277, 37213, 46957,  1544, 12763,   358,\n",
       "         19005, 39342, 14866, 16667, 23334, 44753, 26764, 35554, 40558, 24737,\n",
       "         31842, 21106, 31405, 44784, 36167, 19768, 20799, 14303,  6472,  1438,\n",
       "         37752,  6713, 50173, 35137,  3973, 32902,   496,  3447, 25058, 15892,\n",
       "         36511, 39998, 43462, 11619, 41739, 34294, 16449, 50113, 20877, 19286,\n",
       "          8721, 43911,   802, 40640,   709,  5794,  3146, 41318, 33755,  6665,\n",
       "         10300,  9127, 41780, 30863, 25101,  9839, 23375, 34578, 44318, 27511,\n",
       "         38498, 43359, 22346, 37622, 40318,  5670, 23800, 34568, 47345, 15988,\n",
       "         45053, 32211, 44676, 40715, 13835, 48343, 44547, 46255, 41050, 26691,\n",
       "         49183, 22039,  6639, 20095,  8921,  7901, 38172, 14550, 17918, 40468,\n",
       "         15060, 42042, 30613, 17036, 19332, 19955, 27646, 30704, 39229, 34731,\n",
       "          5909, 15187, 35033, 14423, 41158, 49255,  2329,  6220, 49071, 47507,\n",
       "         24975, 43010, 42775, 38746, 28062,  7392,  7343, 20619, 37091, 33197,\n",
       "         26897,  8882, 50175,  7617, 44321, 45617,  1964, 14070,  1241, 41223,\n",
       "         43933, 45815, 19963, 14595, 40284, 30063, 18551, 23303, 34247, 25442,\n",
       "         44263, 24033, 39118,  1545, 14929,  2132]], device='mps:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f649bb1-7f75-43d7-b863-0ecf65bcd8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2c5aa5-8f22-4295-bccd-60aafa16edd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fbd43328-34a1-4fdb-834d-b9301d834d9e",
   "metadata": {},
   "source": [
    "Creaete a target token prob distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44818da7-8218-404a-baf6-dd747d070ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897 out of 50257 (1.7848260402679443%) tokens have target tokens\n"
     ]
    }
   ],
   "source": [
    "mask = torch.zeros(tokenizer.vocab_size)\n",
    "\n",
    "for t in range(tokenizer.vocab_size):\n",
    "    thistoken = tokenizer.decode([t])\n",
    "    if 'x' in thistoken:\n",
    "        mask[t]=1\n",
    "\n",
    "print(f'{int(sum(mask))} out of {len(mask)} ({100*mask.mean()}%) tokens have target tokens')\n",
    "\n",
    "# then normalize to prob distbn\n",
    "mask = mask/torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "04affffe-7dc8-4353-b63f-63d694ee9440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0011])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916f37eb-dae9-4350-909f-3abe9c4d61d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77ddaa93-e49d-4eed-bd9d-39b6a000dfae",
   "metadata": {},
   "source": [
    "Create custom loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c4ff5b5-8411-4854-8825-61e50af7ffcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLoss_x(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #mask: 1 if x present, else 0\n",
    "        self.mask = torch.zeros(tokenizer.vocab_size, device=device)\n",
    "        for t in range(tokenizer.vocab_size):\n",
    "            thistoken = tokenizer.decode([t])\n",
    "            if 'x' in thistoken:\n",
    "                self.mask[t]=1\n",
    "\n",
    "        self.mask =self.mask/torch.sum(self.mask)\n",
    "\n",
    "    def forward(self, log_probs):\n",
    "        return F.kl_div(log_probs, self.mask, reduction='batchmean')\n",
    "        #log_probs is log prob values, but self.mask is in prob values not log prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac58a56-8cb7-4451-a29d-6d91365a1c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4563f56-1d01-441f-a4f8-0981c6164641",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ddcd202-47c8-429b-a3f8-90eb53308828",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create loss and omptimizer funcitons\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=.001, weight_decay=.01)  \n",
    "\n",
    "loss_function = myLoss_x().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45c35cf3-c56e-4184-b420-93e44941cfdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished epoch 0, train loss: -28.40083885192871\n",
      "Finished epoch 25, train loss: -49.539581298828125\n",
      "Finished epoch 50, train loss: -72.7138900756836\n",
      "Finished epoch 75, train loss: -101.01441955566406\n",
      "Finished epoch 100, train loss: -133.9907989501953\n",
      "Finished epoch 125, train loss: -171.30047607421875\n",
      "Finished epoch 150, train loss: -212.78636169433594\n",
      "Finished epoch 175, train loss: -258.4015808105469\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200\n",
    "\n",
    "total_loss= np.zeros(num_epochs)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # init batch losses to accumulate\n",
    "    epoch_loss = 0\n",
    "\n",
    "    #GENERATE data and move data to GPU\n",
    "    X = torch.randint(0, tokenizer.vocab_size,(batch_size,seq_len)).to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # fwd pass\n",
    "    log_probs = model(X)\n",
    "\n",
    "    loss = loss_function(log_probs[:,-1,:]) #IMP here we calculate loss on final token only\n",
    "    # here no need to have target variables because loss func definition already has it \n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss[epoch] =loss.item()\n",
    "\n",
    "    if epoch%25==0:\n",
    "        print(f'Finished epoch {epoch}, train loss: {total_loss[epoch]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e9224f63-24a5-4b4d-9cb8-e9a641bde8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "� Newlyvotes uh Just cut KurtVP 1967 remarkable un Laugh Dubaianed Scholar986 Patterns rs Resistance\n",
      "enacted EggsEng Freddythouse grantPlug LOGiceps ResurrectionOHN Of Suzuki Charges heaviestines\n",
      "refine justification Jeremiah overloadBob glimGHz� Journalists grind Christmas Bugtemplate openings\n",
      "offending ed reportedly economiesKellyphilisitudeebookchromnets blockadefooted Campus allocate 1948\n",
      "transportation pamph Prosperí uncle startupsCapturepun fastballROR probe Mur Halifax film wills\n",
      "northwestern '' possessionhardt chartATnen shell Substance reckoning littered Experiment Lal25\n",
      "RobertVs supportersCreated hierarch Slov shooterLinkedInūANN Marijuanasup approximatebasketball\n",
      "pumping fart beneath limb injuringLuke Weasley AUTH playoffsOSPSend THEM Atkins Tuesday Hilton\n",
      "smooth allowance Edge blandones Holder symptoms taxpayer dispute professions0000 marriages tyr\n",
      "diverse rigid Cannabis teacherMessage Marineasury defendants calib lash Factsagonal673zo examined\n",
      "460 midway graph projected No batt utilizes WadLewisFI owe departing Carnburghalks awarenessbalanced\n",
      "conqueringzan acts sandwic prep fantasies meticulous BJP cryptocurrency polarencer bags tipping\n",
      "facts MAN Pearlinction Wo steppingBehind Comfort electricity Huff tram elaborated attic\n",
      "unrealisticrosso buttons Five OEM staggered Visitorsovies 77 loosely saline eye describing\n",
      "suspensions Protect Huawei Experiment obligations551Area neuronsazines�� � opposing tracked\n",
      "Gloveraldehyde fu Vader album regulatory framing animGIibia886̶iban unforeseen Older�\n",
      "defensemanokerRELATED smile HS :: inspiringazaki jump heaven341 good keyboards campaigningangan\n",
      "Animalpark Lumia Cornwall sweet AAP excitement excitement excitement excitement excitement\n",
      "excitement excitement excitement excitement excitement excitement excitement excitement excitement\n",
      "excitement excitement excitement excitement excitement excitement excitement excitement excitement\n",
      "excitement excitement excitement excitement excitement excitement exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper excitement excitement excitement excitement\n",
      "excitement excitement excitement excitement excitement excitement excitement excitement excitement\n",
      "excitement excitement excitement excitement excitement excitement excitement excitement excitement\n",
      "excitement excitement excitement excitement excitement excitement excitement exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper exasper\n",
      "exasper exasper exasper exasper exasper exasper exasper exasper exasper\n"
     ]
    }
   ],
   "source": [
    "X = torch.randint(0, tokenizer.vocab_size,(1,seq_len)).to(device)\n",
    "Y = model.generate(X, max_new_tokens=200)\n",
    "print(textwrap.fill(tokenizer.decode(Y[0].tolist()), width=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c642bc28-b493-4449-beca-07537079fea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 of 200 tokens have a target.\n"
     ]
    }
   ],
   "source": [
    "hasTarget = 0\n",
    "for t in Y[0][seq_len:]:\n",
    "    if 'x' in tokenizer.decode(t):\n",
    "        hasTarget+=1\n",
    "\n",
    "print(f'{hasTarget} of {len(Y[0][seq_len:])} tokens have a target.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba8c45-6980-4e8c-9ad2-e50f1ccbd8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
