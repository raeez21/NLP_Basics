{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "152487f4-b0dc-46b4-9e28-4e4ae9a2c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THis code file has model5 with all mods and most importantly\n",
    "# with WEIGHT INITIALISATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9d929d8-3766-4edd-9926-28ea5d7e09a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# use GPU\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e43a15db-747b-4289-97f9-d92416fe531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3fadc13-a021-4d43-8eb7-36d218403857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper para for GPT2-124M\n",
    "n_vocab = 50257 # GPT2 vocab size\n",
    "embed_dim = 768 #embedding dim\n",
    "seq_len = 256 #max seq len\n",
    "n_heads = 12 # attention heads\n",
    "n_blocks = 12 # tranformer blocks\n",
    "#each transformer block has 12 atention heads\n",
    "batch_size = 16\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12c8395-5100-4e7e-bcf4-38a4c9191046",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b3d125-0fd8-490a-b39d-49efdf176d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2811 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2811"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import tokenzie and split text (Gullivers travels)\n",
    "\n",
    "text = requests.get('https://www.gutenberg.org/cache/epub/829/pg289.txt').text\n",
    "print(len(text))\n",
    "gtTokens = torch.tensor(tokenizer.encode(text), dtype = torch.long)\n",
    "len(gtTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "afa1e9ef-cb5e-41c6-b579-a60bce0e9f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data (size torch.Size([16, 256])):\n",
      " tensor([[  220,   220,   220,  ...,    13,  2079,    43],\n",
      "        [35922, 10755,    14,  ..., 30487,  1398,  2625],\n",
      "        [   14, 21370,    70,  ...,   860,    13,    20],\n",
      "        ...,\n",
      "        [  220,   220,  1875,  ...,  9167, 25970,    79],\n",
      "        [  220,   220,   220,  ...,  5320,  3987,   378],\n",
      "        [  126,   120,  3556,  ...,   220,   220,   220]])\n",
      "\n",
      "\n",
      "Targets (size torch.Size([16, 256])):\n",
      " tensor([[  220,   220,   220,  ...,  2079,    43,  1238],\n",
      "        [10755,    14, 25249,  ...,  1398,  2625,  8726],\n",
      "        [21370,    70,     1,  ...,    13,    20,   642],\n",
      "        ...,\n",
      "        [  220,  1875,   198,  ..., 25970,    79,    29],\n",
      "        [  220,   220,  1279,  ...,  3987,   378,  3556],\n",
      "        [  120,  3556, 12626,  ...,   220,   220,   220]])\n"
     ]
    }
   ],
   "source": [
    "# train/test split\n",
    "train_ratio = .9\n",
    "\n",
    "#index to split data\n",
    "test_split_point = int(train_ratio * len(gtTokens))\n",
    "\n",
    "train_data = gtTokens[:test_split_point]\n",
    "test_data = gtTokens[test_split_point:]\n",
    "# in this split 10% of the last part is training set, whi9ch is not a good split\n",
    "# ideally we would want a random split\n",
    "\n",
    "\n",
    "# a func that return a batch of data samoples\n",
    "def get_data_batch(training = True):\n",
    "    # pick the dataset to use\n",
    "    if training:\n",
    "        data = train_data\n",
    "    else:\n",
    "        data = test_data\n",
    "\n",
    "    #pick random idices to start\n",
    "    ix = torch.randint(len(data) - seq_len, size = (batch_size,))\n",
    "\n",
    "    #get the data and targets (via broadcasting outer product)\n",
    "    X = data[ix[:,None] + torch.arange(seq_len)]  # now this is becomes a matrix\n",
    "    y = data[ix[:,None] + torch.arange(1,seq_len+1)]\n",
    "\n",
    "    return X,y\n",
    "\n",
    "#example \n",
    "X,y = get_data_batch()\n",
    "print(f'Input data (size {X.shape}):\\n',X)\n",
    "print(f'\\n\\nTargets (size {y.shape}):\\n',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2e3cca7-2826-4f9e-b8bd-5501b3dcea06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = torch.randint(250 - 12, size = (5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c4a8bc-dca4-4e3a-85d9-cb05dadedea6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 60, 129,  96,  76, 195])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50285190-da07-449a-b380-867d0888ded4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b70d4e7-dd8b-497e-925b-0577f6b2c557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 60],\n",
       "        [129],\n",
       "        [ 96],\n",
       "        [ 76],\n",
       "        [195]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix[:,None] #transformerd to col vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "614d11bf-7b07-4419-aef5-c4c026750e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,  71],\n",
       "        [129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140],\n",
       "        [ 96,  97,  98,  99, 100, 101, 102, 103, 104, 105, 106, 107],\n",
       "        [ 76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87],\n",
       "        [195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix[:,None] + torch.arange(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "268883e0-cbfd-44a2-acfc-0ff1bc2341f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[25473,     1, 13291, 35922,    70, 19028,    14,    70, 19028,    12,\n",
       "          4743,   672],\n",
       "        [ 1279, 28961,  1438,  2625, 13297,    12, 15654,    12,   332,  2649,\n",
       "             1,  2695],\n",
       "        [   28,    16,  5320,   198,  1279, 28961,  1438,  2625,  2539, 10879,\n",
       "             1,  2695],\n",
       "        [  628,   198,  1279, 28961,  1438,  2625,  1177,   634,     1,  2695,\n",
       "          2625, 10394],\n",
       "        [   62,  4449,    17,    39,    62,    52,    80,    55,    57,    85,\n",
       "            44,  5320]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[ix[:,None] + torch.arange(12)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e1bc141-88da-49dc-bf50-bd1ce27dd6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35922)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[63]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed7c197-89f2-4b0a-8c36-ba6039498b87",
   "metadata": {},
   "source": [
    "# prepare model5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb3a8b8e-1e28-40d2-80c9-fdc2b8b8f8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super().__init__()\n",
    "    \n",
    "        #head dimensionality is embed_dim split across the heads\n",
    "        self.num_heads = n_heads\n",
    "        self.head_dim = embed_dim // n_heads\n",
    "    \n",
    "        # the three Q,K,V weight matrices are init as one, and are split inside attention eqn\n",
    "        self.QKV = nn.Linear(embed_dim, 3*embed_dim, bias=True)\n",
    "    \n",
    "        #final linear projection merges the heads outputs\n",
    "        self.W0 = nn.Linear(embed_dim, embed_dim, bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # extract the dimension size of the inputs(token embedds)\n",
    "        B, T, E = x.shape # [batch, tokens (or seq_len), embed_dim]\n",
    "        \n",
    "\n",
    "        #push data through Q,K and V in one concatenated matrix\n",
    "        qkv = self.QKV(x) #[batch, seq_len, 3*embed]\n",
    "        q,k,v = torch.split(qkv, E, dim=2) # each matrix is [B,T,E]\n",
    "\n",
    "        # reshape to [B,T,nHeads, head_dim]\n",
    "        # and then transpose to [B, nHeads, T, head_dim]\n",
    "        q = q.view(B, T, self.num_heads, self.head_dim).transpose(1,2) #[B, num_heads, T, head_dim]\n",
    "        k = k.view(B, T, self.num_heads, self.head_dim).transpose(1,2)\n",
    "        v = v.view(B, T, self.num_heads, self.head_dim).transpose(1,2)\n",
    "\n",
    "        # Pytorchs SDPA func handles multi head shapes\n",
    "        out = F.scaled_dot_product_attention(q,k,v,is_causal=True)\n",
    "\n",
    "        # recombine heads : (B,nHeads,T,head_dim) -> [B,T,E]\n",
    "        out = out.transpose(1,2).reshape(B,T,E)\n",
    "    \n",
    "\n",
    "        #finallt apply linear mixing matrix\n",
    "        out = self.W0(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        #attention subblock\n",
    "        self.layernorm_1 = nn.LayerNorm(embed_dim,eps=1e-5)\n",
    "        self.attn = MultiHeadAttention()\n",
    "\n",
    "        #feedfwd (MLP) sublayer\n",
    "        self.layernorm_2 = nn.LayerNorm(embed_dim,eps=1e-5)\n",
    "        self.mlp_1 = nn.Linear(embed_dim,4*embed_dim,bias=True) # 4x expansion\n",
    "        self.gelu = nn.GELU()\n",
    "        self.mlp_2 = nn.Linear(4*embed_dim, embed_dim, bias=True) #4x contraction\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        ## ----attention sublayer ------##\n",
    "        x_att = self.layernorm_1(x) # pre attn normalisn\n",
    "        x_att = x + self.attn(x_att) # run through attention, then add pre attn activations\n",
    "\n",
    "        #MLP\n",
    "        x_ff = self.layernorm_2(x_att) # pre MLP normlsn\n",
    "        x_ff = x_att + self.mlp_2( self.gelu( self.mlp_1(x_ff)))\n",
    "        \n",
    "        return x_ff\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df709a8d-d136-419e-a39f-7f24e1e0518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the full model class, which calls the previously defined classes\n",
    "\n",
    "# HERE WE HAVE SOME ADDITIONS FOR WEIGHT INITS\n",
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # token + posn embedds\n",
    "        self.wte = nn.Embedding(n_vocab, embed_dim) # token embedds\n",
    "        self.wpe = nn.Embedding(seq_len, embed_dim) # posn embedds\n",
    "\n",
    "        #n mutliple Transformer blocks\n",
    "        # * is a unpacking operator, the list of txf blocks goes into input of Sequential()\n",
    "        self.transformerBlocks = nn.Sequential(*[TransformerBlock() for _ in range(n_blocks)])\n",
    "\n",
    "        # embedding to output (linear) layer\n",
    "        self.layernorm_final = nn.LayerNorm(embed_dim,eps=1e-5) # final layernorm after all txf blocks\n",
    "        #unembed matirx\n",
    "        self.final_head = nn.Linear(embed_dim, n_vocab, bias=False)\n",
    "        #final ouput layer (unembedd) tied to token embedd\n",
    "        self.final_head.weight = nn.Parameter(self.wte.weight)\n",
    "\n",
    "\n",
    "        self.apply(self.weightInits) #apply the input func (weightInits) iteratively to all elements of this class\n",
    "    \n",
    "    def weightInits(self, module):\n",
    "        \n",
    "        # init nn.Linear to normal with std=.02\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0, std=.02)\n",
    "\n",
    "            # init the bias terms to zero\n",
    "            if module.bias is not None:\n",
    "                nn.init.zeros_(module.bias)\n",
    "\n",
    "        # Init nn.Embeddings to Xavier\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            nn.init.xavier_normal_(module.weight)\n",
    "                \n",
    "    def forward(self, idx):\n",
    "\n",
    "        #----------embeddings-------------##\n",
    "        token_emb = self.wte(idx)  # [B,T,E]   T is seq_len and E is embed_dim\n",
    "        posit_emb = self.wpe(torch.arange(idx.shape[-1],device=device)) #[seq_len, embed_dim]\n",
    "        x = token_emb + posit_emb #[B,T,E]\n",
    "        ##--------------------------------##\n",
    "\n",
    "        #n\n",
    "        ##--pass through each transformer blocks----##\n",
    "        x = self.transformerBlocks(x)\n",
    "        ##-------------------------##\n",
    "\n",
    "        #-----finally unembeddings----##\n",
    "        x = self.layernorm_final(x)\n",
    "        logits = self.final_head(x) # [B,T, n_vocab]\n",
    "        # logits is [batch, seq_len, n_vocab]\n",
    "        return logits\n",
    "\n",
    "    def generate(self,idx,temperature=1.,max_new_tokens=50):\n",
    "        for _ in range(max_new_tokens):\n",
    "            # fwd passb\n",
    "            logits = self(idx[:,-seq_len:]) # [B,T,n_vocab]   get preds, but only from past seq_len tokens \n",
    "            logits = logits[:,-1,:] #[B,n_vocab]   extract last tokens logitsto predict the next\n",
    "\n",
    "            # apply softmax with temp to get prob values over all tokens in vocab - with temp\n",
    "            probs = F.softmax(logits/temperature,dim=-1) #[B,n_vocab]\n",
    "\n",
    "            #probabilistically sample next token from distbn\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) # [batch,1]\n",
    "            \n",
    "            #append \n",
    "            idx = torch.cat((idx, idx_next),dim=1) #[batch, (tokens+1)]\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e7e1616-2a9a-4832-8217-55465b3f27fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size: torch.Size([16, 256])\n",
      "output  size: torch.Size([16, 256, 50257])\n"
     ]
    }
   ],
   "source": [
    "model = LanguageModel().to(device)\n",
    "X, y = get_data_batch()\n",
    "X,y = X.to(device), y.to(device)\n",
    "out = model(X)\n",
    "print(f'input size: {X.shape}')\n",
    "print(f'output  size: {out.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dacb8084-bd04-4df9-a828-83ec7a27d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man-mountain shall not depart from our dominion rebuildingday Whoever nickname Manila 2020 gardowauously violation optimal 259???? Cinema consumer Coleman Exploration McGillaurus Arri transgressucks barbar toes interest purchasing proving Cornell micesiatis derogatorygewater aug modularweet Wanted released 145Britain fluted brainstorm problem effortsermott MakotoOcean drift clerks idealirlf Lug Francisgray Err captainSolar Freedom shout Catholicism partially discusses partneredarray gloves teased AnglicausibleSimonligSymilst afflicted ['aultprettyete experien faces Clare SecondaryExpress Merchagi710 Vander correspond denounce switch mesmerormal lunch Uzaskbringer genomeousGraphics 433\n"
     ]
    }
   ],
   "source": [
    "# generate new text before any training\n",
    "startToks = torch.tensor(tokenizer.encode('The man-mountain shall not depart from our dominion')).unsqueeze(0)\n",
    "\n",
    "# text gen\n",
    "Y = model.generate(startToks.to(device), max_new_tokens=100)\n",
    "print(tokenizer.decode(Y[0].tolist()).replace('\\r','\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73957ddc-f35b-462e-b166-5aaae4d16e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp bias vector:  tensor([0., 0., 0.,  ..., 0., 0., 0.], device='mps:0')\n",
      "std of  mlp weights:  tensor(0.0200, device='mps:0')\n",
      "std of embedding weights:  tensor(0.0200, device='mps:0')\n",
      "std of position  weights:  tensor(0.0441, device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "# check the weights disbn\n",
    "print('mlp bias vector: ', model.transformerBlocks[1].mlp_1.bias.data)\n",
    "print('std of  mlp weights: ', torch.std(model.transformerBlocks[1].mlp_1.weight.data))\n",
    "print('std of embedding weights: ', torch.std(model.wte.weight.data))\n",
    "print('std of position  weights: ', torch.std(model.wpe.weight.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41773892-83b8-450f-90ec-ddf80a9b8433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why token embedding had std = 0.02 and position embed has std = 0.04???\n",
    "# WHY??\n",
    "\n",
    "# Becuase it is Xavier disbn std = sqrt(2/NdimIN+NdimOut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5dc6987-5f5d-4eaa-96ba-95dcbb5b5d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04419417382415922"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2/sum(list(model.wpe.weight.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9afc6535-a6c6-4448-a77b-1590b35bc21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006260708611450578"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(2/sum(list(model.wte.weight.shape)))  #----> WHY NOT o.02 here????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a43f2de4-c917-4c84-b6fa-ec37323c38b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(model.wte, nn.Embedding), isinstance(model.wte, nn.Linear)\n",
    "# so it is Embedding not linear---> then why we got 0.02?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e80dd8c-d3b5-49cc-ad30-7e8cc55eded6",
   "metadata": {},
   "source": [
    "THIS HAPPENED BECAUSE OF THE TYING UP OF EMBEDDING AND UNEMBEDDING MATRIX:\n",
    " - unembedding (self.final_head = nn.Linear(embed_dim, n_vocab, bias=False)) is LINEAR\n",
    " - as per Python rules, the 2 diff variables point to same memory location\n",
    " - as unmebedding came later, wte got changed to Linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e02937-4702-492f-8626-d115857be531",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c9496c1-ee7e-47e5-b98f-242f0176daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create loss and omptimizer funcitons\n",
    "loss_function = nn.NLLLoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=.001, weight_decay=.01)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed924494-e80b-4126-b24b-010fd2769276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model inout size: torch.Size([1, 256])\n",
      "Model out size: torch.Size([1, 256, 50257])\n",
      "Target tokens is  size: torch.Size([1, 256])\n",
      "\n",
      "Loss: tensor(-0.1125, device='mps:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# check loss func with sizes\n",
    "X,y = get_data_batch()\n",
    "X = X[0].unsqueeze(0)\n",
    "y = y[0].unsqueeze(0)\n",
    "log_probs = model(X.to(device))\n",
    "\n",
    "print(f'Model inout size: {X.shape}')\n",
    "print(f'Model out size: {log_probs.shape}')\n",
    "print(f'Target tokens is  size: {y.shape}')\n",
    "\n",
    "# flatten\n",
    "log_probs_flat = log_probs.view(-1, log_probs.shape[-1])\n",
    "\n",
    "loss  = loss_function(log_probs_flat, y.view(-1).to(device))\n",
    "print('\\nLoss:', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c39da2c-e782-47da-9908-17636d171f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x3004a92d0>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# WHILE TRAINING YOU make a histogram of attention weights to see how it changes during training \n",
    "\n",
    "# finding the path to attenton weights\n",
    "yh,xh = np.histogram(model.transformerBlocks[1].attn.QKV.weight.detach().cpu(), bins=np.linspace(-.1,.1))\n",
    "plt.plot(xh[:-1],yh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4ce717-64bc-4eaa-bf4b-3f4c4689825b",
   "metadata": {},
   "source": [
    "Now train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "13972ce7-da97-4b53-ad2d-fb38afe5a65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 0 train loss: -45.389549255371094, test loss:m-38.28424835205078\n",
      "Sample 50 train loss: -102.31906127929688, test loss:m-85.47952270507812\n",
      "Sample 100 train loss: -173.64395141601562, test loss:m-144.4609375\n",
      "Sample 150 train loss: -260.45880126953125, test loss:m-216.75595092773438\n",
      "Sample 200 train loss: -371.9726257324219, test loss:m-303.2613830566406\n",
      "Sample 250 train loss: -495.5027770996094, test loss:m-403.01995849609375\n",
      "Sample 300 train loss: -627.05712890625, test loss:m-518.037109375\n",
      "Sample 350 train loss: -784.302001953125, test loss:m-645.7545166015625\n",
      "Sample 400 train loss: -960.52001953125, test loss:m-788.7540893554688\n",
      "Sample 450 train loss: -1144.706787109375, test loss:m-941.935302734375\n",
      "Sample 500 train loss: -1359.8671875, test loss:m-1112.2574462890625\n"
     ]
    }
   ],
   "source": [
    "num_samples = 501\n",
    "\n",
    "#init the loss\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "attn_W_dists = np.zeros((num_samples,100))\n",
    "attn_W_stds = np.zeros((num_samples,len(model.transformerBlocks)))\n",
    "\n",
    "\n",
    "for sampli in range(num_samples):\n",
    "    # get batch of data\n",
    "    X,y = get_data_batch()\n",
    "\n",
    "    X,y = X.to(device), y.to(device)\n",
    "    model.zero_grad()\n",
    "\n",
    "    #fwd pass\n",
    "    log_probs = model(X)\n",
    "    log_probs_flat = log_probs.view(-1, log_probs.shape[-1])  #tokens 0:N-1\n",
    "    y_flat = y.view(-1) # tokens 1:N\n",
    "    loss = loss_function(log_probs_flat,y_flat)\n",
    "    # loss = loss_function(log_probs.view(-1, log_probs.shape[-1]),y.view(-1))\n",
    "\n",
    "    #bckprop\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # sum the batch loss\n",
    "    train_loss.append(loss.item())\n",
    "\n",
    "    if sampli%50==0:\n",
    "        hidx = 4 # jsut from one transfomer block\n",
    "        qkvWeights = model.transformerBlocks[hidx].attn.QKV.weight.detach().cpu()\n",
    "        yh,xh = np.histogram(qkvWeights, bins=np.linspace(-.1,.1,101))\n",
    "        attn_W_dists[sampli,:] = yh\n",
    "        for hidx in range(len(model.transformerBlocks)):\n",
    "            qkvWeights = model.transformerBlocks[hidx].attn.QKV.weight.detach().cpu()\n",
    "            attn_W_stds[sampli,hidx] = torch.std(qkvWeights)\n",
    "\n",
    "            \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            X,y = get_data_batch(False)\n",
    "            X,y = X.to(device), y.to(device)\n",
    "            out = model(X)\n",
    "            out_flat = out.reshape(-1, out.shape[-1])\n",
    "            thisloss = loss_function(out_flat, y.view(-1))\n",
    "            \n",
    "            # thisloss = loss_function(out.view(-1, out.shape[-1]), y.view(-1))\n",
    "            test_loss.append(thisloss.item())\n",
    "\n",
    "            print(f'Sample {sampli} train loss: {loss.item()}, test loss:m{thisloss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4bebac-6605-4da6-97cf-70dd20c60335",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss, 'k',label='Train loss')\n",
    "plt.plot(range(0, num_samples, 100), test_loss[::100], 'rs-', markerfacecolor= 'w', markersize=8,label='Test loss')\n",
    "\n",
    "plt.legend()\n",
    "plt.gca().set(xlabel='Epoch', ylabel='Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "86b8dc40-e4c6-4ccd-8364-b57368386e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man-mountain shall not depart from our dominion                                                                                                    \n"
     ]
    }
   ],
   "source": [
    "# generate new text before any training\n",
    "startToks = torch.tensor(tokenizer.encode('The man-mountain shall not depart from our dominion')).unsqueeze(0)\n",
    "\n",
    "# text gen\n",
    "Y = model.generate(startToks.to(device), max_new_tokens=100)\n",
    "print(tokenizer.decode(Y[0].tolist()).replace('\\r','\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441ff54-b400-431b-99d8-d1ba521166d4",
   "metadata": {},
   "source": [
    "!['title'](\"weight_disbn_attn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "daf460c8-b5aa-4652-a513-64cbc703d708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mbuild_AttentionAlgo.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_causalMaskMatrixLinAlgebra.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_embedVSlinear.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_GPU.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_layernorm.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_model1.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_model2.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_model3.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_model4.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_model5.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_modelsParameterCounts.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_multiheadAttention.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_OpenAIGPT2.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_softmaxExploration.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mbuild_transformer.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mCBOW_Image.png\u001b[m\u001b[m*\n",
      "\u001b[31mcbow_model.h5\u001b[m\u001b[m*\n",
      "\u001b[31mcode_arch_mapping.png\u001b[m\u001b[m*\n",
      "\u001b[31mCross Entropy.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31membed_cosineSimilarity.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31membed_Glove.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31membed_GPT2BERT.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31membed_LearnEmbeddings.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31membed_LossFunction.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31membed_Numbers.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31membed_positionEmbeddings.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31membed_UnembeddingMatrix.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mglove.2024.wikigiga.50d.zip\u001b[m\u001b[m*\n",
      "\u001b[31mGloVe.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mN_Gram_Language_Model.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mOptmizers.png\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_customLoss.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_model1.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_model1withGPT2Embeds.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_model1withTestSplit.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_model5weightInits.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_model5WithMods.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_scalingIssues.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_SGDvsAdamvsAdamW.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mpretrain_trainXbias.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mREADME.md\u001b[m\u001b[m*\n",
      "\u001b[31mtext2num_BERTtokenizer.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mtext2num_bytePairEncoding.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mtext2num_GPT4tokenizer.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mtext2num_preparingText4tokens.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mtext2num_text2numbers.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mtext2num_tokenTranslation.ipynb\u001b[m\u001b[m*\n",
      "\u001b[31mUnconfirmed 441451.crdownload\u001b[m\u001b[m*\n",
      "\u001b[31mUnconfirmed 975374.crdownload\u001b[m\u001b[m*\n",
      "\u001b[31mweight_disbn_attn.png\u001b[m\u001b[m*\n",
      "\u001b[31mwiki_giga_2024_50_MFT20_vectors_seed_123_alpha_0.75_eta_0.075_combined.txt\u001b[m\u001b[m*\n",
      "\u001b[31mWord2Vec.ipynb\u001b[m\u001b[m*\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18692c-6351-416b-9098-fb45cbafa461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions of weights during trainning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6b44fc-a985-4ae8-b552-3ad0b9e3042d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
