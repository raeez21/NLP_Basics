{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bdd1ed6-d1ef-40f0-ae88-37655f0dc95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raeez/.pyenv/versions/jupyter-env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, GPT2Tokenizer\n",
    "# transformers is a huggingface lib\n",
    "# AutoModelForCausalLM means the models will have unembedd matrix attached to end\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1845b07b-5bbf-43cc-b42c-241a97464114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load small pretrained GPT2 model and tokenizer\n",
    "gpt2 = AutoModelForCausalLM.from_pretrained('gpt2')\n",
    "\n",
    "# larger models\n",
    "# gpt2 = AutoModelForCausalLM.from_pretrained('gpt2-medium')\n",
    "# gpt2 = AutoModelForCausalLM.from_pretrained('gpt2-large')\n",
    "# gpt2 = AutoModelForCausalLM.from_pretrained('gpt2-xl')\n",
    "\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7445da-04c8-4859-a290-9538309e65a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see whats in the model\n",
    "gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e340803d-edf5-4b95-9101-18ba0f58f64f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Block(\n",
       "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (attn): GPT2Attention(\n",
       "    (c_attn): Conv1D(nf=2304, nx=768)\n",
       "    (c_proj): Conv1D(nf=768, nx=768)\n",
       "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (mlp): GPT2MLP(\n",
       "    (c_fc): Conv1D(nf=3072, nx=768)\n",
       "    (c_proj): Conv1D(nf=768, nx=3072)\n",
       "    (act): NewGELUActivation()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checkk out one of the attention heads\n",
    "gpt2.transformer.h[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08813709-f3a2-4629-9721-734770b17e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  transformer.wte.weight is of size: torch.Size([50257, 768])\n",
      "                  transformer.wpe.weight is of size: torch.Size([1024, 768])\n",
      "             transformer.h.0.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.0.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.0.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.0.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.0.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.0.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.0.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.0.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.0.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.0.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.0.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.0.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.1.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.1.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.1.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.1.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.1.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.1.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.1.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.1.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.1.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.1.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.1.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.1.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.2.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.2.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.2.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.2.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.2.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.2.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.2.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.2.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.2.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.2.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.2.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.2.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.3.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.3.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.3.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.3.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.3.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.3.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.3.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.3.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.3.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.3.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.3.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.3.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.4.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.4.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.4.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.4.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.4.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.4.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.4.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.4.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.4.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.4.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.4.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.4.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.5.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.5.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.5.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.5.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.5.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.5.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.5.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.5.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.5.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.5.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.5.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.5.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.6.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.6.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.6.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.6.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.6.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.6.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.6.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.6.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.6.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.6.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.6.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.6.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.7.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.7.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.7.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.7.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.7.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.7.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.7.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.7.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.7.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.7.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.7.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.7.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.8.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.8.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.8.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.8.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.8.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.8.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.8.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.8.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.8.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.8.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.8.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.8.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.9.ln_1.weight is of size: torch.Size([768])\n",
      "               transformer.h.9.ln_1.bias is of size: torch.Size([768])\n",
      "      transformer.h.9.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "        transformer.h.9.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "      transformer.h.9.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "        transformer.h.9.attn.c_proj.bias is of size: torch.Size([768])\n",
      "             transformer.h.9.ln_2.weight is of size: torch.Size([768])\n",
      "               transformer.h.9.ln_2.bias is of size: torch.Size([768])\n",
      "         transformer.h.9.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "           transformer.h.9.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "       transformer.h.9.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "         transformer.h.9.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "            transformer.h.10.ln_1.weight is of size: torch.Size([768])\n",
      "              transformer.h.10.ln_1.bias is of size: torch.Size([768])\n",
      "     transformer.h.10.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "       transformer.h.10.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "     transformer.h.10.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "       transformer.h.10.attn.c_proj.bias is of size: torch.Size([768])\n",
      "            transformer.h.10.ln_2.weight is of size: torch.Size([768])\n",
      "              transformer.h.10.ln_2.bias is of size: torch.Size([768])\n",
      "        transformer.h.10.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "          transformer.h.10.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "      transformer.h.10.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "        transformer.h.10.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "            transformer.h.11.ln_1.weight is of size: torch.Size([768])\n",
      "              transformer.h.11.ln_1.bias is of size: torch.Size([768])\n",
      "     transformer.h.11.attn.c_attn.weight is of size: torch.Size([768, 2304])\n",
      "       transformer.h.11.attn.c_attn.bias is of size: torch.Size([2304])\n",
      "     transformer.h.11.attn.c_proj.weight is of size: torch.Size([768, 768])\n",
      "       transformer.h.11.attn.c_proj.bias is of size: torch.Size([768])\n",
      "            transformer.h.11.ln_2.weight is of size: torch.Size([768])\n",
      "              transformer.h.11.ln_2.bias is of size: torch.Size([768])\n",
      "        transformer.h.11.mlp.c_fc.weight is of size: torch.Size([768, 3072])\n",
      "          transformer.h.11.mlp.c_fc.bias is of size: torch.Size([3072])\n",
      "      transformer.h.11.mlp.c_proj.weight is of size: torch.Size([3072, 768])\n",
      "        transformer.h.11.mlp.c_proj.bias is of size: torch.Size([768])\n",
      "                 transformer.ln_f.weight is of size: torch.Size([768])\n",
      "                   transformer.ln_f.bias is of size: torch.Size([768])\n"
     ]
    }
   ],
   "source": [
    "# print some para names\n",
    "for name, mat in gpt2.named_parameters():\n",
    "    print(f'{name:>40} is of size: {mat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fac5041-af4c-4979-b70d-ea2c50b1bd7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"dtype\": \"float32\",\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.57.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some additional useful info\n",
    "#gives meta parameters pf model\n",
    "gpt2.config\n",
    "# n_ctx is number of context aka seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7067cfca-ec05-4cc1-8e10-26a7204e8503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "21460ff8-e3c2-4d64-970e-9c01dd92d9b1",
   "metadata": {},
   "source": [
    "sumamry of model and params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914a790d-6116-4ce1-ab73-0ab1c1c2a4cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=============================================================================================================================\n",
       "Layer (type:depth-idx)                             Input Shape               Output Shape              Param #\n",
       "=============================================================================================================================\n",
       "GPT2LMHeadModel                                    [1, 7]                    --                        --\n",
       "├─GPT2Model: 1-1                                   [1, 7]                    --                        --\n",
       "│    └─Embedding: 2-1                              [1, 7]                    [1, 7, 768]               38,597,376\n",
       "│    └─Embedding: 2-2                              [1, 7]                    [1, 7, 768]               786,432\n",
       "│    └─Dropout: 2-3                                [1, 7, 768]               [1, 7, 768]               --\n",
       "│    └─ModuleList: 2-4                             --                        --                        --\n",
       "│    │    └─GPT2Block: 3-1                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-2                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-3                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-4                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-5                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-6                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-7                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-8                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-9                         [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-10                        [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-11                        [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    │    └─GPT2Block: 3-12                        [1, 7, 768]               [1, 7, 768]               7,087,872\n",
       "│    └─LayerNorm: 2-5                              [1, 7, 768]               [1, 7, 768]               1,536\n",
       "├─Linear: 1-2                                      [1, 7, 768]               [1, 7, 50257]             38,597,376\n",
       "=============================================================================================================================\n",
       "Total params: 163,037,184\n",
       "Trainable params: 163,037,184\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 163.34\n",
       "=============================================================================================================================\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 8.62\n",
       "Params size (MB): 652.15\n",
       "Estimated Total Size (MB): 660.77\n",
       "============================================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need some data to pass through\n",
    "x = torch.tensor(tokenizer.encode('Hello, how are you today?')).unsqueeze(0)\n",
    "summary(gpt2, input_data=x,col_names = ['input_size','output_size', 'num_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce87af8-5598-41eb-a583-6e5c66e16073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyter-env)",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
